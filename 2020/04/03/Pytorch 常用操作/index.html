<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Pytorch常用操作 | BaiDing's blog</title><meta name="description" content="Pytorch常用操作"><meta name="keywords" content="Pytorch"><meta name="author" content="白丁"><meta name="copyright" content="白丁"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://raw.githubusercontent.com/BaiDingHub/Blog_images/master/BlogSource/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="crossorigin"/><link rel="preconnect" href="http://ta.qq.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="x-1ef6P_miWkq-RJn_fmjd3KYumrXANNXYzK1myaLf0"/><meta name="baidu-site-verification" content="guD6l44Chk"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Pytorch常用操作"><meta name="twitter:description" content="Pytorch常用操作"><meta name="twitter:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true"><meta property="og:type" content="article"><meta property="og:title" content="Pytorch常用操作"><meta property="og:url" content="http://baidinghub.github.io/2020/04/03/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"><meta property="og:site_name" content="BaiDing's blog"><meta property="og:description" content="Pytorch常用操作"><meta property="og:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css" ><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://baidinghub.github.io/2020/04/03/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"><link rel="prev" title="Pytorch保存和加载预训练模型" href="http://baidinghub.github.io/2020/04/03/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><link rel="next" title="Google使用教程" href="http://baidinghub.github.io/2020/04/03/Google%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-162698439-1', 'auto');
ga('send', 'pageview');
</script><script src="https://tajs.qq.com/stats?sId=66540586" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"4JGH9NW4XG","apiKey":"41cdb6d9ec4d21196956524e9c985b36","indexName":"baiding","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/avatar.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/friend_404.gif?raw=true'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">93</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">60</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-指定GPU编号"><span class="toc-text">1.指定GPU编号</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2、查看模型每层输出详情"><span class="toc-text">2、查看模型每层输出详情</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3、梯度裁剪（Gradient-Clipping）"><span class="toc-text">3、梯度裁剪（Gradient Clipping）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4、学习率衰减"><span class="toc-text">4、学习率衰减</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5、在不同的层使用不同的学习率"><span class="toc-text">5、在不同的层使用不同的学习率</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6、冻结某些层的参数"><span class="toc-text">6、冻结某些层的参数</span></a></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">BaiDing's blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Pytorch常用操作</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-04-03 11:00:05"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-04-03</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-12-02 11:11:09"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-12-02</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/">Pytorch</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">2k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 7 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2020/04/03/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#post-comment"><span class="gitalk-comment-count comment-count"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><h1 id="1-指定GPU编号"><a href="#1-指定GPU编号" class="headerlink" title="1.指定GPU编号"></a>1.指定GPU编号</h1><p><strong>第一种方法</strong></p>
<ul>
<li>设置当前使用的GPU设备仅为0号设备，设备名称为 <code>/gpu:0</code>：<code>os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;0&quot;</code></li>
<li><p>设置当前使用的GPU设备为0,1号两个设备，名称依次为 <code>/gpu:0</code>、<code>/gpu:1</code>： <code>os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;0,1&quot;</code> ，根据顺序表示优先使用0号设备,然后使用1号设备。</p>
<p> 注：指定GPU的命令需要放在和神经网络相关的一系列操作的前面。</p>
</li>
</ul>
<p><strong>第二种方法</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device_ids = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">model = model.cuda(device_ids[<span class="number">0</span>])  //将模型及参数主要放置在<span class="number">0</span>号卡</span><br><span class="line"><span class="keyword">if</span> len(device_ids) &gt; <span class="number">1</span>:</span><br><span class="line">    self.model = nn.DataParallel(model, device_ids=device_ids) //使用多个GPU并行运算</span><br></pre></td></tr></table></figure>
<h1 id="2、查看模型每层输出详情"><a href="#2、查看模型每层输出详情" class="headerlink" title="2、查看模型每层输出详情"></a>2、查看模型每层输出详情</h1><p>  查看模型每层输出详情</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchsummary <span class="keyword">import</span> summary</span><br><span class="line">summary(your_model, input_size=(channels, H, W))</span><br></pre></td></tr></table></figure>
<h1 id="3、梯度裁剪（Gradient-Clipping）"><a href="#3、梯度裁剪（Gradient-Clipping）" class="headerlink" title="3、梯度裁剪（Gradient Clipping）"></a>3、梯度裁剪（Gradient Clipping）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">outputs = model(data)</span><br><span class="line">loss= loss_fn(outputs, target)</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">loss.backward()</span><br><span class="line">nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">20</span>, norm_type=<span class="number">2</span>)</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>
<p><code>nn.utils.clip_grad_norm_</code> 的参数：</p>
<ul>
<li><strong>parameters</strong> – 一个基于变量的迭代器，会进行梯度归一化</li>
<li><strong>max_norm</strong> – 梯度的最大范数</li>
<li><strong>norm_type</strong> – 规定范数的类型，默认为L2</li>
</ul>
<p><code>不椭的椭圆</code> 提出：梯度裁剪在某些任务上会额外消耗大量的计算时间，可移步评论区查看详情</p>
<h1 id="4、学习率衰减"><a href="#4、学习率衰减" class="headerlink" title="4、学习率衰减"></a>4、学习率衰减</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练前的初始化</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">scheduler = lr_scheduler.StepLR(optimizer, <span class="number">10</span>, <span class="number">0.1</span>)  <span class="comment"># # 每过10个epoch，学习率乘以0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练过程中</span></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> n_epoch:</span><br><span class="line">    scheduler.step()</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>可用的学习率衰减方法</p>
<ul>
<li>等间隔调整学习率 StepLR</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=<span class="number">0.1</span>, last_epoch=<span class="number">-1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">等间隔调整学习率，调整倍数为 gamma 倍，调整间隔为 step_size。间隔单位是step。需要注意的是， step 通常是指 epoch，不要弄成 iteration 了。</span></span><br><span class="line"><span class="string">##########################################################</span></span><br><span class="line"><span class="string">step_size(int)- 学习率下降间隔数，若为 30，则会在 30、 60、 90…个 step 时，将学习率调整为 lr*gamma。</span></span><br><span class="line"><span class="string">gamma(float)- 学习率调整倍数，默认为 0.1 倍，即下降 10 倍。</span></span><br><span class="line"><span class="string">last_epoch(int)- 上一个 epoch 数，这个变量用来指示学习率是否需要调整。当last_epoch 符合设定的间隔时，就会对学习率进行调整。当为-1 时，学习率设置为初始值。</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<ul>
<li>按需调整学习率 MultiStepLR</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=<span class="number">0.1</span>, last_epoch=<span class="number">-1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">按设定的间隔调整学习率。这个方法适合后期调试使用，观察 loss 曲线，为每个实验定制学习率调整时机。</span></span><br><span class="line"><span class="string">##########################################################</span></span><br><span class="line"><span class="string">milestones(list)- 一个 list，每一个元素代表何时调整学习率， list 元素必须是递增的。如 milestones=[30,80,120]</span></span><br><span class="line"><span class="string">gamma(float)- 学习率调整倍数，默认为 0.1 倍，即下降 10 倍。</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<ul>
<li>指数衰减调整学习率 ExponentialLR</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch=<span class="number">-1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">按指数衰减调整学习率，调整公式: lr=lr∗gamma∗∗epoch lr = lr * gamma**epoch</span></span><br><span class="line"><span class="string">gamma- 学习率调整倍数的底，指数为 epoch，即 gamma**epoch</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<ul>
<li>余弦退火调整学习率 CosineAnnealingLR</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=<span class="number">0</span>, last_epoch=<span class="number">-1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">以余弦函数为周期，并在每个周期最大值时重新设置学习率。以初始学习率为最大学习率，以 2∗T_max 为周期，在一个周期内先下降，后上升。</span></span><br><span class="line"><span class="string">##########################################################</span></span><br><span class="line"><span class="string">T_max(int)- 一次学习率周期的迭代次数，即 T_max 个 epoch 之后重新设置学习率。</span></span><br><span class="line"><span class="string">eta_min(float)- 最小学习率，即在一个周期中，学习率最小会下降到 eta_min，默认值为 0。</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<ul>
<li>自适应调整学习率 ReduceLROnPlateau</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">'min'</span>, factor=<span class="number">0.1</span>, patience=<span class="number">10</span>, verbose=<span class="literal">False</span>, threshold=<span class="number">0.0001</span>, threshold_mode=<span class="string">'rel'</span>, cooldown=<span class="number">0</span>, min_lr=<span class="number">0</span>, eps=<span class="number">1e-08</span>)</span><br><span class="line"> </span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">当某指标不再变化（下降或升高），调整学习率，这是非常实用的学习率调整策略。</span></span><br><span class="line"><span class="string">##########################################################</span></span><br><span class="line"><span class="string">mode(str)- 模式选择，有 min 和 max 两种模式， min 表示当指标不再降低(如监测loss)， max 表示当指标不再升高(如监测 accuracy)。</span></span><br><span class="line"><span class="string">factor(float)- 学习率调整倍数(等同于其它方法的 gamma)，即学习率更新为 lr = lr * factor</span></span><br><span class="line"><span class="string">patience(int)- 忍受该指标多少个 step 不变化，当忍无可忍时，调整学习率。</span></span><br><span class="line"><span class="string">verbose(bool)- 是否打印学习率信息， print(‘Epoch &#123;:5d&#125;: reducing learning rate of group &#123;&#125; to &#123;:.4e&#125;.’.format(epoch, i, new_lr))</span></span><br><span class="line"><span class="string">threshold_mode(str)- 选择判断指标是否达最优的模式，有两种模式， rel 和 abs。</span></span><br><span class="line"><span class="string">当 threshold_mode == rel，并且 mode == max 时， dynamic_threshold = best * ( 1 +threshold )；</span></span><br><span class="line"><span class="string">当 threshold_mode == rel，并且 mode == min 时， dynamic_threshold = best * ( 1 -threshold )；</span></span><br><span class="line"><span class="string">当 threshold_mode == abs，并且 mode== max 时， dynamic_threshold = best + threshold ；</span></span><br><span class="line"><span class="string">当 threshold_mode == rel，并且 mode == max 时， dynamic_threshold = best - threshold；</span></span><br><span class="line"><span class="string">threshold(float)- 配合 threshold_mode 使用。</span></span><br><span class="line"><span class="string">cooldown(int)- “冷却时间“，当调整学习率之后，让学习率调整策略冷静一下，让模型再训练一段时间，再重启监测模式。</span></span><br><span class="line"><span class="string">min_lr(float or list)- 学习率下限，可为 float，或者 list，当有多个参数组时，可用 list 进行设置。</span></span><br><span class="line"><span class="string">eps(float)- 学习率衰减的最小值，当学习率变化小于 eps 时，则不调整学习率。</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<ul>
<li>自定义调整学习率 LambdaLR</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=<span class="number">-1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">为不同参数组设定不同学习率调整策略。调整规则为，</span></span><br><span class="line"><span class="string">lr=base_lr∗lmbda(self.last_epoch)</span></span><br><span class="line"><span class="string">fine-tune 中十分有用，我们不仅可为不同的层设定不同的学习率，还可以为其设定不同的学习率调整策略。</span></span><br><span class="line"><span class="string">##########################################################</span></span><br><span class="line"><span class="string">lr_lambda(function or list)- 一个计算学习率调整倍数的函数，输入通常为 step，当有多个参数组时，设为 list。</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<h1 id="5、在不同的层使用不同的学习率"><a href="#5、在不同的层使用不同的学习率" class="headerlink" title="5、在不同的层使用不同的学习率"></a>5、在不同的层使用不同的学习率</h1><p>我们对模型的不同层使用不同的学习率。</p>
<p>还是使用这个模型作为例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">net = Network()  <span class="comment"># 获取自定义网络结构</span></span><br><span class="line"><span class="keyword">for</span> name, value <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    print(<span class="string">'name: &#123;&#125;'</span>.format(name))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line"><span class="comment"># name: cnn.VGG_16.convolution1_1.weight</span></span><br><span class="line"><span class="comment"># name: cnn.VGG_16.convolution1_1.bias</span></span><br><span class="line"><span class="comment"># name: cnn.VGG_16.convolution1_2.weight</span></span><br><span class="line"><span class="comment"># name: cnn.VGG_16.convolution1_2.bias</span></span><br><span class="line"><span class="comment"># name: cnn.VGG_16.convolution2_1.weight</span></span><br><span class="line"><span class="comment"># name: cnn.VGG_16.convolution2_1.bias</span></span><br><span class="line"><span class="comment"># name: cnn.VGG_16.convolution2_2.weight</span></span><br><span class="line"><span class="comment"># name: cnn.VGG_16.convolution2_2.bias</span></span><br></pre></td></tr></table></figure>
<p>对 convolution1 和 convolution2 设置不同的学习率，首先将它们分开，即放到不同的列表里：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">conv1_params = []</span><br><span class="line">conv2_params = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, parms <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">"convolution1"</span> <span class="keyword">in</span> name:</span><br><span class="line">        conv1_params += [parms]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        conv2_params += [parms]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后在优化器中进行如下操作：</span></span><br><span class="line">optimizer = optim.Adam(</span><br><span class="line">    [</span><br><span class="line">        &#123;<span class="string">"params"</span>: conv1_params, <span class="string">'lr'</span>: <span class="number">0.01</span>&#125;,</span><br><span class="line">        &#123;<span class="string">"params"</span>: conv2_params, <span class="string">'lr'</span>: <span class="number">0.001</span>&#125;,</span><br><span class="line">    ],</span><br><span class="line">    weight_decay=<span class="number">1e-3</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>我们将模型划分为两部分，存放到一个列表里，每部分就对应上面的一个字典，在字典里设置不同的学习率。当这两部分有相同的其他参数时，就将该参数放到列表外面作为全局参数，如上面的<code>weight_decay</code>。</p>
<p>也可以在列表外设置一个全局学习率，当各部分字典里设置了局部学习率时，就使用该学习率，否则就使用列表外的全局学习率。</p>
<h1 id="6、冻结某些层的参数"><a href="#6、冻结某些层的参数" class="headerlink" title="6、冻结某些层的参数"></a>6、冻结某些层的参数</h1><p>在加载预训练模型的时候，我们有时想冻结前面几层，使其参数在训练过程中不发生变化。</p>
<p>我们需要先知道每一层的名字，通过如下代码打印：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net = Network()  <span class="comment"># 获取自定义网络结构</span></span><br><span class="line"><span class="keyword">for</span> name, value <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    print(<span class="string">'name: &#123;0&#125;,\t grad: &#123;1&#125;'</span>.format(name, value.requires_grad))</span><br></pre></td></tr></table></figure>
<p>假设前几层信息如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">name: cnn.VGG_16.convolution1_1.weight,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution1_1.bias,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution1_2.weight,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution1_2.bias,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution2_1.weight,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution2_1.bias,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution2_2.weight,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution2_2.bias,	 grad: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>后面的True表示该层的参数可训练，然后我们定义一个要冻结的层的列表：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">no_grad = [</span><br><span class="line">    <span class="string">'cnn.VGG_16.convolution1_1.weight'</span>,</span><br><span class="line">    <span class="string">'cnn.VGG_16.convolution1_1.bias'</span>,</span><br><span class="line">    <span class="string">'cnn.VGG_16.convolution1_2.weight'</span>,</span><br><span class="line">    <span class="string">'cnn.VGG_16.convolution1_2.bias'</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p><strong>冻结方法</strong>如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">net = Net.CTPN()  <span class="comment"># 获取网络结构</span></span><br><span class="line"><span class="keyword">for</span> name, value <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> name <span class="keyword">in</span> no_grad:</span><br><span class="line">        value.requires_grad = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        value.requires_grad = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>冻结后我们再打印每层的信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">name: cnn.VGG_16.convolution1_1.weight,	 grad: <span class="literal">False</span></span><br><span class="line">name: cnn.VGG_16.convolution1_1.bias,	 grad: <span class="literal">False</span></span><br><span class="line">name: cnn.VGG_16.convolution1_2.weight,	 grad: <span class="literal">False</span></span><br><span class="line">name: cnn.VGG_16.convolution1_2.bias,	 grad: <span class="literal">False</span></span><br><span class="line">name: cnn.VGG_16.convolution2_1.weight,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution2_1.bias,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution2_2.weight,	 grad: <span class="literal">True</span></span><br><span class="line">name: cnn.VGG_16.convolution2_2.bias,	 grad: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>可以看到前两层的weight和bias的requires_grad都为False，表示它们不可训练。</p>
<p>最后在定义优化器时，只对requires_grad为True的层的参数进行更新。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.Adam(filter(<span class="keyword">lambda</span> p: p.requires_grad, net.parameters()), lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">白丁</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://baidinghub.github.io/2020/04/03/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/">http://baidinghub.github.io/2020/04/03/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://baidinghub.github.io" target="_blank">BaiDing's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Pytorch/">Pytorch</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDyIdOn/M/aXcGQOiSDVMqvN2gxDdiESHUfFuB2YMy48fvNN9SZOQUbVlGF4Pk6nDXIAir+br/EWuEnNLtgOCYMo/BTxl29gqS/QGHPiDaIQedzmLcuRZpfDuGit61N/b9pyktpZLagBgbl5Ox9mAgWQxXyhxYB092gyOXqrBULBeZUYQ+H7Eupha10QTQghHv4nLk+oYWo2UXEiijQpE3qMXT32G8v8k0KbRdd1hIFPyNEx6eZ6Buc2ZdbMtoutdGjvdnw5B1+dxgl1egESPChzcwCMxt3NW/3faQ5lsjRhQD4fRU+Ua/aqXe+0xg2+xr0BTjNr/JZIAaNiLuo71lH 1564026260@qq.com" async="async"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/wechat.png?raw=true" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/alipay.jpg?raw=true" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/04/03/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><img class="prev_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/cover.jpg?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Pytorch保存和加载预训练模型</div></div></a></div><div class="next-post pull_right"><a href="/2020/04/03/Google%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"><img class="next_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%95%99%E7%A8%8B/%E5%85%B6%E4%BB%96%E8%BD%AF%E4%BB%B6/Google%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/cover.jpg?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Google使用教程</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/03/Pytorch保存和加载预训练模型/" title="Pytorch保存和加载预训练模型"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/cover.jpg?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">Pytorch保存和加载预训练模型</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'd3948be001a91411dfd9',
  clientSecret: 'ebddf2a2a5a039922fb373a8a8c0efcc439bf6ca',
  repo: 'BaiDingHub.github.io',
  owner: 'BaiDingHub',
  admin: ['BaiDingHub'],
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 白丁</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://jerryc.me/" target="_blank" rel="noopener">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js" ></script><script src="/js/utils.js" ></script><script src="/js/main.js" ></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/search/algolia.js"></script></body></html>