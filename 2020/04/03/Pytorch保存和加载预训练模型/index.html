<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Pytorch保存和加载预训练模型 | BaiDing's blog</title><meta name="description" content="Pytorch保存和加载预训练模型"><meta name="keywords" content="Pytorch"><meta name="author" content="白丁"><meta name="copyright" content="白丁"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://raw.githubusercontent.com/BaiDingHub/Blog_images/master/BlogSource/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="crossorigin"/><link rel="preconnect" href="http://ta.qq.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="x-1ef6P_miWkq-RJn_fmjd3KYumrXANNXYzK1myaLf0"/><meta name="baidu-site-verification" content="guD6l44Chk"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Pytorch保存和加载预训练模型"><meta name="twitter:description" content="Pytorch保存和加载预训练模型"><meta name="twitter:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/cover.jpg?raw=true"><meta property="og:type" content="article"><meta property="og:title" content="Pytorch保存和加载预训练模型"><meta property="og:url" content="http://baidinghub.github.io/2020/04/03/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><meta property="og:site_name" content="BaiDing's blog"><meta property="og:description" content="Pytorch保存和加载预训练模型"><meta property="og:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/cover.jpg?raw=true"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css" ><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://baidinghub.github.io/2020/04/03/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><link rel="prev" title="具体的训练小技巧" href="http://baidinghub.github.io/2020/04/03/%E5%85%B7%E4%BD%93%E7%9A%84%E8%AE%AD%E7%BB%83Trick/"><link rel="next" title="Pytorch常用操作" href="http://baidinghub.github.io/2020/04/03/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-162698439-1', 'auto');
ga('send', 'pageview');
</script><script src="https://tajs.qq.com/stats?sId=66540586" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"4JGH9NW4XG","apiKey":"41cdb6d9ec4d21196956524e9c985b36","indexName":"baiding","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/avatar.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/friend_404.gif?raw=true'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">92</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">57</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">16</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#预训练模型使用的场景"><span class="toc-text">预训练模型使用的场景</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#预训练模型的方法"><span class="toc-text">预训练模型的方法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实现预训练模型的加载（pytorch）"><span class="toc-text">实现预训练模型的加载（pytorch）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#直接加载预训练模型"><span class="toc-text">直接加载预训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#修改某一层"><span class="toc-text">修改某一层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#加载部分预训练模型"><span class="toc-text">加载部分预训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#保存加载模型基本用法"><span class="toc-text">保存加载模型基本用法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#保存加载自定义模型"><span class="toc-text">保存加载自定义模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#跨设备保存加载模型"><span class="toc-text">跨设备保存加载模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CUDA-的用法"><span class="toc-text">CUDA 的用法</span></a></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/cover.jpg?raw=true)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">BaiDing's blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Pytorch保存和加载预训练模型</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-04-03 11:01:05"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-04-03</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-12-02 11:11:09"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-12-02</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/">Pytorch</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">2.4k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 8 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2020/04/03/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#post-comment"><span class="gitalk-comment-count comment-count"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><h1 id="预训练模型使用的场景"><a href="#预训练模型使用的场景" class="headerlink" title="预训练模型使用的场景"></a>预训练模型使用的场景</h1><hr>
<blockquote>
<p>声明：该部分有部分参考，若有侵权，请及时告知</p>
</blockquote>
<p> 简单来说，预训练模型(pre-trained model)是前人为了解决类似问题所创造出来的模型。你在解决问题的时候，不用从零开始训练一个新模型，可以从在类似问题中训练过的模型入手。</p>
<p><strong>**场景一</strong>：数据集小，数据相似度高(与pre-trained model的训练数据相比而言)**<br>在这种情况下，因为数据与预训练模型的训练数据相似度很高，因此我们不需要重新训练模型。我们只需要将输出层改制成符合问题情境下的结构就好。</p>
<p>我们使用预处理模型作为模式提取器。</p>
<p>比如说我们使用在ImageNet上训练的模型来辨认一组新照片中的小猫小狗。在这里，需要被辨认的图片与ImageNet库中的图片类似，但是我们的输出结果中只需要两项——猫或者狗。</p>
<p>在这个例子中，我们需要做的就是把dense layer和最终softmax layer的输出从1000个类别改为2个类别。</p>
<p><strong>**场景二</strong>：数据集小，数据相似度不高**</p>
<p>在这种情况下，我们可以冻结预训练模型中的前k个层中的权重，然后重新训练后面的n-k个层，当然最后一层也需要根据相应的输出格式来进行修改。</p>
<p>因为数据的相似度不高，重新训练的过程就变得非常关键。而新数据集大小的不足，则是通过冻结预训练模型的前k层进行弥补。</p>
<p><strong>场景三：数据集大，数据相似度不高</strong></p>
<p>在这种情况下，因为我们有一个很大的数据集，所以神经网络的训练过程将会比较有效率。然而，因为实际数据与预训练模型的训练数据之间存在很大差异，采用预训练模型将不会是一种高效的方式。</p>
<p>因此最好的方法还是将预处理模型中的权重全都初始化后在新数据集的基础上重头开始训练。</p>
<p><strong>场景四：数据集大，数据相似度高</strong></p>
<p>这就是最理想的情况，采用预训练模型会变得非常高效。最好的运用方式是保持模型原有的结构和初始权重不变，随后在新数据集的基础上重新训练。</p>
<h1 id="预训练模型的方法"><a href="#预训练模型的方法" class="headerlink" title="预训练模型的方法"></a>预训练模型的方法</h1><hr>
<p><strong>特征提取</strong></p>
<p>我们可以将预训练模型当做特征提取装置来使用。具体的做法是，将输出层去掉，然后将剩下的整个网络当做一个固定的特征提取机，从而应用到新的数据集中。</p>
<p><strong>采用预训练模型的结构</strong></p>
<p>我们还可以采用预训练模型的结构，但先将所有的权重随机化，然后依据自己的数据集进行训练。</p>
<p><strong>训练特定层，冻结其他层</strong></p>
<p>另一种使用预训练模型的方法是对它进行部分的训练。具体的做法是，将模型起始的一些层的权重保持不变，重新训练后面的层，得到新的权重。在这个过程中，我们可以多次进行尝试，从而能够依据结果找到frozen layers和retrain layers之间的最佳搭配。</p>
<p>如何使用与训练模型，是由数据集大小和新旧数据集(预训练的数据集和我们要解决的数据集)之间数据的相似度来决定的。</p>
<h1 id="实现预训练模型的加载（pytorch）"><a href="#实现预训练模型的加载（pytorch）" class="headerlink" title="实现预训练模型的加载（pytorch）"></a>实现预训练模型的加载（pytorch）</h1><hr>
<p>先附上<a href="https://pytorch-cn.readthedocs.io/zh/latest/torchvision/torchvision-models/" target="_blank" rel="noopener">pytorch官方中文文档</a>、<a href="https://github.com/pytorch/vision/tree/master/torchvision" target="_blank" rel="noopener">torchvision的github地址</a></p>
<h3 id="直接加载预训练模型"><a href="#直接加载预训练模型" class="headerlink" title="直接加载预训练模型"></a>直接加载预训练模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import torchvision.models as models</span><br><span class="line"></span><br><span class="line">model &#x3D; models.resnet101(pretrained&#x3D;True)</span><br></pre></td></tr></table></figure>
<h3 id="修改某一层"><a href="#修改某一层" class="headerlink" title="修改某一层"></a>修改某一层</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import torchvision.models as models</span><br><span class="line"> </span><br><span class="line">model &#x3D; models.resnet101(pretrained&#x3D;True)</span><br><span class="line"></span><br><span class="line">model.fc &#x3D; nn.Linear(2048, 120)  #120为样本分类数目,修改最后的分类的全连接层</span><br><span class="line">model.conv1 &#x3D; nn.Conv2d(3, 64,kernel_size&#x3D;5, stride&#x3D;2, padding&#x3D;3, bias&#x3D;False)   #修改中间层</span><br></pre></td></tr></table></figure>
<h3 id="加载部分预训练模型"><a href="#加载部分预训练模型" class="headerlink" title="加载部分预训练模型"></a>加载部分预训练模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#加载model，model是自己定义好的模型</span><br><span class="line">resnet50 &#x3D; models.resnet50(pretrained&#x3D;True) </span><br><span class="line">model &#x3D;Net(...) </span><br><span class="line"> </span><br><span class="line">#读取参数 </span><br><span class="line">pretrained_dict &#x3D;resnet50.state_dict() </span><br><span class="line">model_dict &#x3D; model.state_dict() </span><br><span class="line"> </span><br><span class="line">#将pretrained_dict里不属于model_dict的键剔除掉 </span><br><span class="line">pretrained_dict &#x3D;  &#123;k: v for k, v in pretrained_dict.items() if k in model_dict&#125; </span><br><span class="line"> </span><br><span class="line"># 更新现有的model_dict </span><br><span class="line">model_dict.update(pretrained_dict) </span><br><span class="line"> </span><br><span class="line"># 加载我们真正需要的state_dict </span><br><span class="line">model.load_state_dict(model_dict)</span><br></pre></td></tr></table></figure>
<h3 id="保存加载模型基本用法"><a href="#保存加载模型基本用法" class="headerlink" title="保存加载模型基本用法"></a>保存加载模型基本用法</h3><p><strong>1、保存加载整个模型</strong>（不推荐）</p>
<p>保存整个网络模型（网络结构+权重参数）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model, <span class="string">'net.pkl'</span>)</span><br></pre></td></tr></table></figure>
<p>直接加载整个网络模型（可能比较耗时）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = torch.load(<span class="string">'net.pkl'</span>)</span><br></pre></td></tr></table></figure>
<p><strong>2、只保存加载模型参数</strong>（推荐）</p>
<p>只保存模型的权重参数（速度快，占内存少）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), <span class="string">'net_params.pkl'</span>)</span><br></pre></td></tr></table></figure>
<p>因为我们只保存了模型的参数，所以需要先定义一个网络对象，然后再加载模型参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建一个网络结构</span></span><br><span class="line">model = ClassNet()</span><br><span class="line"><span class="comment"># 将模型参数加载到新模型中</span></span><br><span class="line">state_dict = torch.load(<span class="string">'net_params.pkl'</span>)</span><br><span class="line">model.load_state_dict(state_dict)</span><br></pre></td></tr></table></figure>
<h3 id="保存加载自定义模型"><a href="#保存加载自定义模型" class="headerlink" title="保存加载自定义模型"></a>保存加载自定义模型</h3><p>上面保存加载的 <code>net.pkl</code> 其实一个字典，通常包含如下内容：</p>
<ol>
<li><strong>网络结构</strong>：输入尺寸、输出尺寸以及隐藏层信息，以便能够在加载时重建模型。</li>
<li><strong>模型的权重参数</strong>：包含各网络层训练后的可学习参数，可以在模型实例上调用 <code>state_dict()</code>方法来获取，比如前面介绍只保存模型权重参数时用到的 <code>model.state_dict()</code>。</li>
<li><strong>优化器参数</strong>：有时保存模型的参数需要稍后接着训练，那么就必须保存优化器的状态和所其使用的超参数，也是在优化器实例上调用 <code>state_dict()</code> 方法来获取这些参数。</li>
<li>其他信息：有时我们需要保存一些其他的信息，比如 <code>epoch</code>，<code>batch_size</code> 等超参数。</li>
</ol>
<p>知道了这些，那么我们就可以自定义需要保存的内容，比如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># saving a checkpoint assuming the network class named ClassNet</span></span><br><span class="line">checkpoint = &#123;<span class="string">'model'</span>: ClassNet(),</span><br><span class="line">              <span class="string">'model_state_dict'</span>: model.state_dict(),</span><br><span class="line">              <span class="string">'optimizer_state_dict'</span>: optimizer.state_dict(),</span><br><span class="line">              <span class="string">'epoch'</span>: epoch&#125;</span><br><span class="line"></span><br><span class="line">torch.save(checkpoint, <span class="string">'checkpoint.pkl'</span>)</span><br></pre></td></tr></table></figure>
<p>上面的 checkpoint 是个字典，里面有4个键值对，分别表示网络模型的不同信息。</p>
<p>然后我们要加载上面保存的自定义的模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_checkpoint</span><span class="params">(filepath)</span>:</span></span><br><span class="line">    checkpoint = torch.load(filepath)</span><br><span class="line">    model = checkpoint[<span class="string">'model'</span>]  <span class="comment"># 提取网络结构</span></span><br><span class="line">    model.load_state_dict(checkpoint[<span class="string">'model_state_dict'</span>])  <span class="comment"># 加载网络权重参数</span></span><br><span class="line">    optimizer = TheOptimizerClass()</span><br><span class="line">    optimizer.load_state_dict(checkpoint[<span class="string">'optimizer_state_dict'</span>])  <span class="comment"># 加载优化器参数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> parameter <span class="keyword">in</span> model.parameters():</span><br><span class="line">        parameter.requires_grad = <span class="literal">False</span></span><br><span class="line">    model.eval()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line">    </span><br><span class="line">model = load_checkpoint(<span class="string">'checkpoint.pkl'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="跨设备保存加载模型"><a href="#跨设备保存加载模型" class="headerlink" title="跨设备保存加载模型"></a>跨设备保存加载模型</h3><p>1、在 CPU 上加载在 GPU 上训练并保存的模型（Save on GPU, Load on CPU）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">'cpu'</span>)</span><br><span class="line">model = TheModelClass()</span><br><span class="line"><span class="comment"># Load all tensors onto the CPU device</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">'net_params.pkl'</span>, map_location=device))</span><br></pre></td></tr></table></figure>
<p><code>map_location</code>：a function, torch.device, string or a dict specifying how to remap storage locations</p>
<p>令 <code>torch.load()</code> 函数的 <code>map_location</code> 参数等于 <code>torch.device(&#39;cpu&#39;)</code> 即可。 这里令 <code>map_location</code> 参数等于 <code>&#39;cpu&#39;</code> 也同样可以。</p>
<p>2、在 GPU 上加载在 GPU 上训练并保存的模型（Save on GPU, Load on GPU）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">model = TheModelClass()</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">'net_params.pkl'</span>))</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure>
<p>在这里使用 <code>map_location</code> 参数不起作用，要使用 <code>model.to(torch.device(&quot;cuda&quot;))</code> 将模型转换为CUDA优化的模型。</p>
<p>还需要对将要输入模型的数据调用 <code>data = data.to(device)</code>，即将数据从CPU转移到GPU。请注意，调用 <code>my_tensor.to(device)</code> 会返回一个 <code>my_tensor</code> 在 GPU 上的副本，它不会覆盖 <code>my_tensor</code>。因此需要手动覆盖张量：<code>my_tensor = my_tensor.to(device)</code>。</p>
<p>3、在 GPU 上加载在 GPU 上训练并保存的模型（Save on CPU, Load on GPU）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">model = TheModelClass()</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">'net_params.pkl'</span>, map_location=<span class="string">"cuda:0"</span>))</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure>
<p>当加载包含GPU tensors的模型时，这些tensors 会被默认加载到GPU上，不过是同一个GPU设备。</p>
<p>当有多个GPU设备时，可以通过将 <code>map_location</code> 设定为 <code>*cuda:device_id*</code> 来指定使用哪一个GPU设备，上面例子是指定编号为0的GPU设备。</p>
<p>其实也可以将 <code>torch.device(&quot;cuda&quot;)</code> 改为 <code>torch.device(&quot;cuda:0&quot;)</code> 来指定编号为0的GPU设备。</p>
<p>最后调用 <code>model.to(torch.device(&#39;cuda&#39;))</code> 来将模型的tensors转换为 CUDA tensors。</p>
<p>下面是PyTorch官方文档上的用法，可以进行参考：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.load(&#39;tensors.pt&#39;)</span><br><span class="line"># Load all tensors onto the CPU</span><br><span class="line">&gt;&gt;&gt; torch.load(&#39;tensors.pt&#39;, map_location&#x3D;torch.device(&#39;cpu&#39;))</span><br><span class="line"># Load all tensors onto the CPU, using a function</span><br><span class="line">&gt;&gt;&gt; torch.load(&#39;tensors.pt&#39;, map_location&#x3D;lambda storage, loc: storage)</span><br><span class="line"># Load all tensors onto GPU 1</span><br><span class="line">&gt;&gt;&gt; torch.load(&#39;tensors.pt&#39;, map_location&#x3D;lambda storage, loc: storage.cuda(1))</span><br><span class="line"># Map tensors from GPU 1 to GPU 0</span><br><span class="line">&gt;&gt;&gt; torch.load(&#39;tensors.pt&#39;, map_location&#x3D;&#123;&#39;cuda:1&#39;:&#39;cuda:0&#39;&#125;)</span><br></pre></td></tr></table></figure>
<h3 id="CUDA-的用法"><a href="#CUDA-的用法" class="headerlink" title="CUDA 的用法"></a>CUDA 的用法</h3><p>在PyTorch中和GPU相关的几个函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># 判断cuda是否可用；</span><br><span class="line">print(torch.cuda.is_available())</span><br><span class="line"></span><br><span class="line"># 获取gpu数量；</span><br><span class="line">print(torch.cuda.device_count())</span><br><span class="line"></span><br><span class="line"># 获取gpu名字；</span><br><span class="line">print(torch.cuda.get_device_name(0))</span><br><span class="line"></span><br><span class="line"># 返回当前gpu设备索引，默认从0开始；</span><br><span class="line">print(torch.cuda.current_device())</span><br></pre></td></tr></table></figure>
<p>有时我们需要把数据和模型从cpu移到gpu中，有以下两种方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">use_cuda &#x3D; torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line"># 方法一：</span><br><span class="line">if use_cuda:</span><br><span class="line">    data &#x3D; data.cuda()</span><br><span class="line">    model.cuda()</span><br><span class="line"></span><br><span class="line"># 方法二：</span><br><span class="line">device &#x3D; torch.device(&quot;cuda&quot; if use_cuda else &quot;cpu&quot;)</span><br><span class="line">data &#x3D; data.to(device)</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure>
<p>个人比较习惯第二种方法，可以少一个 if 语句。而且该方法还可以通过设备号指定使用哪个GPU设备，比如使用0号设备：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device &#x3D; torch.device(&quot;cuda:0&quot; if use_cuda else &quot;cpu&quot;)</span><br></pre></td></tr></table></figure>
<p><strong>参考</strong>：<br>[<a href="https://zhuanlan.zhihu.com/p/73893187" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/73893187</a>]</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">白丁</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://baidinghub.github.io/2020/04/03/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">http://baidinghub.github.io/2020/04/03/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://baidinghub.github.io" target="_blank">BaiDing's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Pytorch/">Pytorch</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDyIdOn/M/aXcGQOiSDVMqvN2gxDdiESHUfFuB2YMy48fvNN9SZOQUbVlGF4Pk6nDXIAir+br/EWuEnNLtgOCYMo/BTxl29gqS/QGHPiDaIQedzmLcuRZpfDuGit61N/b9pyktpZLagBgbl5Ox9mAgWQxXyhxYB092gyOXqrBULBeZUYQ+H7Eupha10QTQghHv4nLk+oYWo2UXEiijQpE3qMXT32G8v8k0KbRdd1hIFPyNEx6eZ6Buc2ZdbMtoutdGjvdnw5B1+dxgl1egESPChzcwCMxt3NW/3faQ5lsjRhQD4fRU+Ua/aqXe+0xg2+xr0BTjNr/JZIAaNiLuo71lH 1564026260@qq.com" async="async"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/wechat.png?raw=true" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/alipay.jpg?raw=true" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/04/03/%E5%85%B7%E4%BD%93%E7%9A%84%E8%AE%AD%E7%BB%83Trick/"><img class="prev_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%85%B7%E4%BD%93%E7%9A%84%E8%AE%AD%E7%BB%83Trick/cover.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">具体的训练小技巧</div></div></a></div><div class="next-post pull_right"><a href="/2020/04/03/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"><img class="next_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Pytorch常用操作</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/03/Pytorch 常用操作/" title="Pytorch常用操作"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">Pytorch常用操作</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'd3948be001a91411dfd9',
  clientSecret: 'ebddf2a2a5a039922fb373a8a8c0efcc439bf6ca',
  repo: 'BaiDingHub.github.io',
  owner: 'BaiDingHub',
  admin: ['BaiDingHub'],
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch/Pytorch%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/cover.jpg?raw=true)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 白丁</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://jerryc.me/" target="_blank" rel="noopener">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js" ></script><script src="/js/utils.js" ></script><script src="/js/main.js" ></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/search/algolia.js"></script></body></html>