<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>对抗样本（八）JSMA | BaiDing's blog</title><meta name="description" content="对抗样本（八）JSMA"><meta name="keywords" content="深度学习,对抗攻击"><meta name="author" content="白丁"><meta name="copyright" content="白丁"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://raw.githubusercontent.com/BaiDingHub/Blog_images/master/BlogSource/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="crossorigin"/><link rel="preconnect" href="http://ta.qq.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="x-1ef6P_miWkq-RJn_fmjd3KYumrXANNXYzK1myaLf0"/><meta name="baidu-site-verification" content="guD6l44Chk"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="对抗样本（八）JSMA"><meta name="twitter:description" content="对抗样本（八）JSMA"><meta name="twitter:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/cover.png?raw=true"><meta property="og:type" content="article"><meta property="og:title" content="对抗样本（八）JSMA"><meta property="og:url" content="http://baidinghub.github.io/2020/04/03/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/"><meta property="og:site_name" content="BaiDing's blog"><meta property="og:description" content="对抗样本（八）JSMA"><meta property="og:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/cover.png?raw=true"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css" ><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://baidinghub.github.io/2020/04/03/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/"><link rel="prev" title="对抗样本（九）C&amp;W’s Attack" href="http://baidinghub.github.io/2020/04/03/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E4%B9%9D%EF%BC%89C&amp;W%E2%80%99s%20Attack/"><link rel="next" title="对抗样本（七）网络蒸馏" href="http://baidinghub.github.io/2020/04/03/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E4%B8%83%EF%BC%89%E7%BD%91%E7%BB%9C%E8%92%B8%E9%A6%8F/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-162698439-1', 'auto');
ga('send', 'pageview');
</script><script src="https://tajs.qq.com/stats?sId=66540586" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"4JGH9NW4XG","apiKey":"41cdb6d9ec4d21196956524e9c985b36","indexName":"baiding","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/avatar.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/friend_404.gif?raw=true'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">97</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">60</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、论文相关信息"><span class="toc-text">一、论文相关信息</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-论文题目"><span class="toc-text">1.论文题目</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-论文时间"><span class="toc-text">2.论文时间</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-论文文献"><span class="toc-text">3.论文文献</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二、论文背景及简介"><span class="toc-text">二、论文背景及简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#三、论文内容总结"><span class="toc-text">三、论文内容总结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#四、论文主要内容"><span class="toc-text">四、论文主要内容</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-text">1. Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Taxonomy-Of-Threat-Models-In-DL"><span class="toc-text">2. Taxonomy Of Threat Models In DL</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Approach"><span class="toc-text">3. Approach</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-Studying-a-Simple-Neural-Network"><span class="toc-text">A. Studying a Simple Neural Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-Generalizing-to-Feedforward-Deep-Nerual-Networks"><span class="toc-text">B. Generalizing to Feedforward Deep Nerual Networks</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Application-Of-The-Approach"><span class="toc-text">4. Application Of The Approach</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Evaluation"><span class="toc-text">5. Evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-对抗样本生成率"><span class="toc-text">A.  对抗样本生成率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-样本的脆弱性"><span class="toc-text">B. 样本的脆弱性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1）类别对研究"><span class="toc-text">1）类别对研究</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2）Hardness标准"><span class="toc-text">2）Hardness标准</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3）adversarial-distance"><span class="toc-text">3）adversarial distance</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Discussion"><span class="toc-text">5. Discussion</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/cover.png?raw=true)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">BaiDing's blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">对抗样本（八）JSMA</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-04-03 13:08:05"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-04-03</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-12-02 11:11:09"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-12-02</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/">对抗样本</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">3.3k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 11 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2020/04/03/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/#post-comment"><span class="gitalk-comment-count comment-count"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><meta name="referrer" content="no-referrer"/>

<h1 id="一、论文相关信息"><a href="#一、论文相关信息" class="headerlink" title="一、论文相关信息"></a>一、论文相关信息</h1><h2 id="1-论文题目"><a href="#1-论文题目" class="headerlink" title="1.论文题目"></a>1.论文题目</h2><p> &emsp;&emsp; <strong>The Limitations of Deep Learning in Adversarial Settings</strong></p>
<h2 id="2-论文时间"><a href="#2-论文时间" class="headerlink" title="2.论文时间"></a>2.论文时间</h2><p> &emsp;&emsp; <strong>2015年</strong></p>
<h2 id="3-论文文献"><a href="#3-论文文献" class="headerlink" title="3.论文文献"></a>3.论文文献</h2><p> &emsp;&emsp; <a href="https://arxiv.org/abs/1511.07528" target="_blank" rel="noopener">https://arxiv.org/abs/1511.07528</a></p>
<h1 id="二、论文背景及简介"><a href="#二、论文背景及简介" class="headerlink" title="二、论文背景及简介"></a>二、论文背景及简介</h1><p> &emsp;&emsp; 在本篇论文中，作者基于对输入和输出的匹配的理解，提出了一个新的生成对抗样本的方法，作者利用了模型对输入样本的<strong>Jacobian矩阵</strong>，同时利用了输入样本的特征。作者定义了一个测量方法用来描述样本类别的脆弱性。作者定义了一个对输入和目标类别的距离计算的方法。</p>
<p><br></p>
<h1 id="三、论文内容总结"><a href="#三、论文内容总结" class="headerlink" title="三、论文内容总结"></a>三、论文内容总结</h1><ul>
<li>作者提出了一个<strong>从样本出发，找到适合的扰动，来进行攻击</strong>的攻击方法。</li>
<li>攻击方法分为三步：<strong>计算Jacobian矩阵，根据Jacobian矩阵得到saliency map，根据saliency map定位要变化的输入特征</strong>。</li>
<li>saliency map表示的是输入样本的特征对类别标签的贡献度</li>
<li>定义了一种测量 一个样本由原始标签攻击成目标标签的难易程度的标准Hardness measure</li>
<li>借助saliency map，定义了一种对输入样本被攻击成某一标签的难易程度的预测的标准</li>
</ul>
<p>附：如需继续学习对抗样本其他内容，请查阅<a href="https://blog.csdn.net/StardustYu/article/details/104410055" target="_blank" rel="noopener">对抗样本学习目录</a></p>
<p><br></p>
<h1 id="四、论文主要内容"><a href="#四、论文主要内容" class="headerlink" title="四、论文主要内容"></a>四、论文主要内容</h1><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p> &emsp;&emsp; 之前的对抗攻击的工作都是使用梯度来进行的。在这片论文中，提出了一个新奇的方法，作者计算了<strong>从输入到输出的一个直接映射</strong>，得到了一个<strong>明确的对抗目标</strong>。而且，这个方法<strong>只需要修改一小部分的输入特征</strong>，就能够得到对抗样本。而且，这个方法也可以使用<strong>启发式的搜索方法</strong>。</p>
<p> &emsp;&emsp; 值得注意的是，我们这个方法是，<strong>构建了一个输入扰动到输出变化的矩阵，也就是首先得到了这个矩阵，再添加对应的扰动使得攻击成功</strong>。而之前提到的方法是根据输出的变化而得到输入的扰动，这两个过程是相反的。我们对输入变化如何影响DNN输出的理解源于对前向导数的评估。</p>
<p> &emsp;&emsp; 我们引入了Jacobian矩阵，前向导数被用来构建对抗性saliency map，用来表示输入特征。saliency map是基于前向导数的多用途工具，会考虑到对抗目标，这在对抗扰动的选择上给予了更多的选择。</p>
<p> &emsp;&emsp; 在我们的工作中，我们考虑到了以下的问题：</p>
<ul>
<li>对抗攻击所需要的最小的knowledge是什么？</li>
<li>怎么样才能识别对抗样本？</li>
<li><p>人类是怎么识别对抗样本的？</p>
<p>&emsp;&emsp; 该方法在LeNet的手写数字是手写识别任务上达到了97.1%的攻击成功率，而且只修改了4.02%的输入特征。且每个样本生成所花费的时间不到1s。</p>
</li>
</ul>
<h2 id="2-Taxonomy-Of-Threat-Models-In-DL"><a href="#2-Taxonomy-Of-Threat-Models-In-DL" class="headerlink" title="2. Taxonomy Of Threat Models In DL"></a>2. Taxonomy Of Threat Models In DL</h2><p> &emsp;&emsp; 这一节主要介绍了DL的基本知识以及对抗目标还有对抗能力（白黑盒攻击）。</p>
<p> &emsp;&emsp; 对抗目标可以分为四类：1.减少输出的confidence，2.无目标攻击，3.有目标攻击，4.<strong>Source/target 攻击</strong>，即使得特定的输入被分类成特定的输出。住：本文的方法就属于source/target 攻击。</p>
<h2 id="3-Approach"><a href="#3-Approach" class="headerlink" title="3. Approach"></a>3. Approach</h2><p> &emsp;&emsp; 在这一节主要介绍了作者的对抗攻击方法。在攻击方法中需要<strong>通过DNN的前向导数构建对抗性saliency map识别与对抗目标相关的输入特征集</strong>。这种方法<strong>既可以用于监督学习也可以用于非监督学习</strong>。</p>
<h3 id="A-Studying-a-Simple-Neural-Network"><a href="#A-Studying-a-Simple-Neural-Network" class="headerlink" title="A. Studying a Simple Neural Network"></a>A. Studying a Simple Neural Network</h3><p> &emsp;&emsp; <strong>简单的模型有助于理解算法的思想</strong>，所以先以简单的模型为例进行讲解。</p>
<p> &emsp;&emsp; 作者训练了一个神经网络去拟合函数$ F(X)=x_1 \wedge x_2$ ，网络输入为$ (x_1,x_2)，x \in [0,1]$ ，输出为$ {0,1}$ ，交运算中采用四舍五入的运算规则，即$ 0.8 \wedge 0.6 = 1$ 。我们现在要对这样一个模型来进行攻击，其问题可以表示为：</p>
<script type="math/tex; mode=display">
arg\ min_{\delta_X}||\delta_X|| \quad s.t.\ F(X+\delta_X) = Y^*</script><p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/1.png?raw=true"  alt="1"></p>
<p> &emsp;&emsp; 我们用函数F的Jacobian矩阵定义前向导数，对该问题而言，其矩阵为：</p>
<script type="math/tex; mode=display">
\nabla F(x) = [\frac{\partial F(x)}{\partial x_1},\frac{\partial F(x)}{\partial x_2}]</script><p> &emsp;&emsp; 这个向量的每一个元素都是可计算的。作者得到的前向导数的值的图像如下：</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/2.png?raw=true"  alt="2"></p>
<p> &emsp;&emsp; <strong>前向导数可以告诉我们哪些输入区域不太可能产生对抗样本</strong>。值越小，越不容易产生。也就是说，当我们去生成对抗样本时，我们要关注那些能够得到更大的前向导数的那部分特征。</p>
<h3 id="B-Generalizing-to-Feedforward-Deep-Nerual-Networks"><a href="#B-Generalizing-to-Feedforward-Deep-Nerual-Networks" class="headerlink" title="B. Generalizing to Feedforward Deep Nerual Networks"></a>B. Generalizing to Feedforward Deep Nerual Networks</h3><p> &emsp;&emsp; 在这一节，我们要将上面的思想拓展到复杂的网络中去。</p>
<p> &emsp;&emsp; 作者所使用的网络以及符号如下：</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/3.png?raw=true"  alt="3"></p>
<p> &emsp;&emsp; 其算法过程如下：</p>
<ol>
<li>定义网络输入$ X$ ，网络输出$ Y$ ，对抗样本$ X<em>$ ，攻击目标$ Y</em>$ ，最大扰动$ \gamma$ ，单次特征扰动参数$ \theta$ 。</li>
<li>首先<strong>计算前向导数</strong>：</li>
</ol>
<script type="math/tex; mode=display">
\nabla F(X) = \frac{\partial F(x)}{\partial x} = [\frac{\partial F_j(x)}{\partial x_i}]_{i \in [1...M],j\in[1...N]}</script><p> &emsp;&emsp; 我们可以通过链式法则，很容易的就能够得到上面的Jacobian矩阵</p>
<ol>
<li><strong>生成saliency maps</strong>，通过saliency maps找到能够最大效率扰动样本的输入特征点。saliency maps是一个根据目标函数自定义的一个矩阵，对于我们的对抗目标而言，对于输入$ X$ ，攻击目标$ t$ ，我们的目标是让$ F_t(x)$ 增大，而使$ F_j(x)  j \ne t$ 减小，知道网络将样本分类为$ t$ 。我们可以通过增加样本特征值，来实现改变其输出概率。我们可以定义该问题的saliency map $ S(X,t)$ 为：</li>
</ol>
<script type="math/tex; mode=display">
S(X,t)[i] = 
\begin{cases}
0 & & if\ \frac{\partial F_t(x)}{\partial X_i}<0\ or\ \sum_{j\ne t}\frac{\partial F_j(x)}{\partial X_i}>0\\
\frac{\partial F_t(x)}{\partial X_i}·|\sum_{j\ne t}\frac{\partial F_j(x)}{\partial X_i}| & & otherwise \\
\end{cases} \\</script><p> &emsp;&emsp; 第一行条件的意思为：只有当$ \frac{\part F_t(x)}{\part X_i}&gt;0$ 时，该单元对增大$ F_t(x)$ 才有帮助，当$ \sum_{j\ne t}\frac{\part F_j(x)}{\part X_i}&lt;0$ 时，该单元才能用来减小其他单元的概率值。</p>
<p> &emsp;&emsp; 也就是说，当$ S(X,t)[i]$ 越大时，增大该特征的值，对抗攻击成功率越大。</p>
<p> &emsp;&emsp; saliency map可以定义多种形式，这对算法是有影响的，作者还提出了下面的一种saliency map：</p>
<script type="math/tex; mode=display">
S(X,t)[i] = 
\begin{cases}
0 & & if\ \frac{\partial F_t(x)}{\partial X_i}》0\ or\ \sum_{j\ne t}\frac{\partial F_j(x)}{\partial X_i}《0\\
|\frac{\partial F_t(x)}{\partial X_i}|·\sum_{j\ne t}\frac{\partial F_j(x)}{\partial X_i} & & otherwise \\
\end{cases} \\</script><p> &emsp;&emsp; 这一个就跟上面那一个刚好相反，也就是说，当$ S(X,t)[i]$ 越大时，减小该特征的值，对抗攻击成功率越大。</p>
<ol>
<li><strong>调整样本</strong>，在确定了要扰动的特征后，我们要对其特征值进行扰动，通过参数$ \theta$ 来修改特征值（相加，例如可取$ \theta=1 or -1$ 。</li>
<li>不断地迭代这个过程，知道修改的总特征值大于最大限制$ \gamma$ ，或者迭代次数达到了最大迭代次数。</li>
</ol>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/4.png?raw=true"  alt="4"></p>
<h2 id="4-Application-Of-The-Approach"><a href="#4-Application-Of-The-Approach" class="headerlink" title="4. Application Of The Approach"></a>4. Application Of The Approach</h2><p> &emsp;&emsp; 在这一节，我们以手写数字识别任务为例，看一下该算法如何应用。</p>
<p> &emsp;&emsp; 在手写识别任务中，每次选取了最大的两个像素点，更改完后，从特征集$ \Gamma$ 中删除，取最大迭代次数为$ |\frac{784·\gamma}{2·100}|$ ，$ \theta$ 可根据我们的生成策略设置$ 1 or  -1$ 。</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/5.png?raw=true"  alt="5"></p>
<p> &emsp;&emsp; 同时，使用该方法，我们可以将一个空白的输入图像一步步的修改为一个分类器可以辨别的图像，以下是进行这样操作得到的类别从0—9的图像。</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/6.png?raw=true"  alt="6"></p>
<h2 id="5-Evaluation"><a href="#5-Evaluation" class="headerlink" title="5. Evaluation"></a>5. Evaluation</h2><p> &emsp;&emsp; 在这一节，主要是在实验的基础上回答了三个问题：</p>
<ul>
<li>上面的算法能够把每一个样本都变成对抗样本？</li>
<li>我们怎样区分样本的脆弱性？</li>
<li>为什么人类能区分对抗样本？（说明了改方法生成的对抗样本在低扰动时可以不被人察觉）</li>
</ul>
<h3 id="A-对抗样本生成率"><a href="#A-对抗样本生成率" class="headerlink" title="A.  对抗样本生成率"></a>A.  对抗样本生成率</h3><p> &emsp;&emsp; 作者在手写数字识别任务上进行了实验，分成3组数据，分别来自于训练集、验证集、测试集，每组10000张图片，为每一张图片生成9个对抗样本（9个其他类别）。这样每一组就会得到90000张对抗样本。设置$ \gamma = 14.5\%$ ，$ \theta = 1$ （采用像素增加的方式）。实验得到，97.1%的对抗样本可以以小于14.5%修改率的结果得到。值得注意的是，输入图像时归一化到[0,1]内的，所以<strong>每次处理像素，都是将像素设置为最高值</strong>。</p>
<p> &emsp;&emsp; 当作者采用$ \theta=-1$ （采用像素减少的方式）时，其攻击成功率只有64.7% ，这可能是因为降低像素会减少输入图片的信息，这让网络难以提取信息，也难以进行分类。</p>
<h3 id="B-样本的脆弱性"><a href="#B-样本的脆弱性" class="headerlink" title="B. 样本的脆弱性"></a>B. 样本的脆弱性</h3><p> &emsp;&emsp; 之前的实验，我们可以得到大约2.9%的图像没有被攻击成功，这表明有一些图像很难被攻击。</p>
<p> &emsp;&emsp; 我们需要研究哪些source-target类别对是最容易被攻击的或者最不容易被攻击的，同时提出了一个hardness测量标准来量化这些现象。通过这些现象我们可以得到一个防御的方法。</p>
<h4 id="1）类别对研究"><a href="#1）类别对研究" class="headerlink" title="1）类别对研究"></a>1）类别对研究</h4><p> &emsp;&emsp; 作者根据攻击情况，得到了下面的图像，行表示初始类别，列表示目标类别，越黑表示攻击成功率越高。</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/7.png?raw=true"  alt="7"></p>
<p> &emsp;&emsp; 从图像中可以看出，初始类别0、2、8不容易被攻击，初始类别1、7、9容易被攻击，很难制作1、7类别的对抗样本，很容易制成0、8、9类别的对抗样本。</p>
<p> &emsp;&emsp; 作者根据每个类别对攻击成功时的平均扰动值，得到了下面的图像</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/8.png?raw=true"  alt="8"></p>
<p> &emsp;&emsp; 可以看到，有着更低扰动的类别对，其攻击成功率越高。</p>
<h4 id="2）Hardness标准"><a href="#2）Hardness标准" class="headerlink" title="2）Hardness标准"></a>2）Hardness标准</h4><p> &emsp;&emsp; 上面的现象驱使着我们要找到一个测量标准来量化两个类别作为source-target攻击的难易度。这对于对抗防御来说是很有用的。</p>
<p> &emsp;&emsp; 该标准是<strong>通过归一化一个类别对相对于其成功率的平均扰动值</strong>得到的。</p>
<script type="math/tex; mode=display">
H(s,t) = \lmoustache_{\tau}\epsilon(s,t,\tau)d \tau</script><p> &emsp;&emsp; 其中$ \epsilon(s,t,\tau)$ 表示在攻击成功率为$ \tau$ 时的平均扰动。<strong>越大表明其越难被攻击</strong></p>
<p> &emsp;&emsp; 在实际情况下，我们可以使用有限个样本计算得到，首先我们定义K个最大可扰动值$ \gamma_k$ ，根据每一个$ r_k$ 生成一组对抗样本，得到改组对抗样本的攻击成功率$ \tau_k$ ，以及平均扰动值$ \epsilon_k$ ，我们就可以计算值：</p>
<script type="math/tex; mode=display">
H(s,t) \thickapprox \sum_{k=1}^{K-1}(\tau_{k+1}-\tau_k)\frac{\epsilon(s,t,\tau_{k+1}+\epsilon(s,t,\tau_{k})}{2}</script><p> &emsp;&emsp; 在本次实验中，我们取$ K=9,\gamma=[0.3,1.3,2.6,5.1,7.7,10.2,12.8,25.5,38.3]\%$ 。得到的Hardness的矩阵图为：</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/9.png?raw=true"  alt="9"></p>
<h4 id="3）adversarial-distance"><a href="#3）adversarial-distance" class="headerlink" title="3）adversarial distance"></a>3）adversarial distance</h4><p> &emsp;&emsp; Hardness有一个很致命的问题，那就是他是在对抗攻击之后计算的，而并不是在对抗攻击前就进行预测。也即是说我们需要一个测量方法，我们预测其输入样本的脆弱性。</p>
<p> &emsp;&emsp; 基于直觉和saliency map，作者得到了测量方法，记为$ A(X,t)$ 表示样本$ X$ 到类别$ t$ 的对抗距离：</p>
<script type="math/tex; mode=display">
A(X,t) = 1-\frac{1}{M}\sum_{i \in 0...M}1_{S(X,t)[i]>0}</script><p> &emsp;&emsp; $ 1_E$ 表示，只有当$ E$ 为true，该式子才为1，否则为0。$ A(X,t)$ 越大，说明$ X$ 越难被攻击为类别$ t$ 。</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/10.png?raw=true"  alt="10"></p>
<p> &emsp;&emsp; 同时作者用该攻击来表示网络$ F$ 的鲁棒性：</p>
<script type="math/tex; mode=display">
R(F) = min_{(X,t)} A(X,t)</script><p> &emsp;&emsp; 该值越大，鲁棒性越好。</p>
<h2 id="5-Discussion"><a href="#5-Discussion" class="headerlink" title="5. Discussion"></a>5. Discussion</h2><p> &emsp;&emsp; 这篇论文假设网络是可导的，同时该论文以LeNet作为Baseline，认为攻击成功LeNet一定可以攻击那些深度模型（博主觉得有点不妥）。</p>
<p> &emsp;&emsp; 与先前的工作相比，这篇论文<strong>从样本出发，找到适合的扰动，来进行攻击</strong>。同时<strong>其攻击方式扰动的输入特征数目较少</strong>。</p>
<p> &emsp;&emsp; <strong>生成Jacobian矩阵的代价很大，该方法的速度也比较慢</strong></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">白丁</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://baidinghub.github.io/2020/04/03/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/">http://baidinghub.github.io/2020/04/03/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://baidinghub.github.io" target="_blank">BaiDing's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/">对抗攻击</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDyIdOn/M/aXcGQOiSDVMqvN2gxDdiESHUfFuB2YMy48fvNN9SZOQUbVlGF4Pk6nDXIAir+br/EWuEnNLtgOCYMo/BTxl29gqS/QGHPiDaIQedzmLcuRZpfDuGit61N/b9pyktpZLagBgbl5Ox9mAgWQxXyhxYB092gyOXqrBULBeZUYQ+H7Eupha10QTQghHv4nLk+oYWo2UXEiijQpE3qMXT32G8v8k0KbRdd1hIFPyNEx6eZ6Buc2ZdbMtoutdGjvdnw5B1+dxgl1egESPChzcwCMxt3NW/3faQ5lsjRhQD4fRU+Ua/aqXe+0xg2+xr0BTjNr/JZIAaNiLuo71lH 1564026260@qq.com" async="async"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/wechat.png?raw=true" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/alipay.jpg?raw=true" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/04/03/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E4%B9%9D%EF%BC%89C&amp;W%E2%80%99s%20Attack/"><img class="prev_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E4%B9%9D%EF%BC%89C&amp;W%E2%80%99s%20Attack/cover.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">对抗样本（九）C&amp;W’s Attack</div></div></a></div><div class="next-post pull_right"><a href="/2020/04/03/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E4%B8%83%EF%BC%89%E7%BD%91%E7%BB%9C%E8%92%B8%E9%A6%8F/"><img class="next_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E4%B8%83%EF%BC%89%E7%BD%91%E7%BB%9C%E8%92%B8%E9%A6%8F/cover.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">对抗样本（七）网络蒸馏</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/03/对抗攻击之目录/" title="对抗样本之目录"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8B%E7%9B%AE%E5%BD%95/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">对抗样本之目录</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/对抗样本（三）FGSM/" title="对抗样本（三）FGSM"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E4%B8%89%EF%BC%89FGSM/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">对抗样本（三）FGSM</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/对抗样本（九）C&W’s Attack/" title="对抗样本（九）C&W’s Attack"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E4%B9%9D%EF%BC%89C&W%E2%80%99s%20Attack/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">对抗样本（九）C&W’s Attack</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/对抗样本（二）L-BFGS/" title="对抗样本（二）L-BFGS"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E4%BA%8C%EF%BC%89L-BFGS/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">对抗样本（二）L-BFGS</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/对抗样本（六）CPPN EA Fool/" title="对抗样本（六）CPPN EA Fool"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AD%EF%BC%89CPPN%20EA%20Fool/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">对抗样本（六）CPPN EA Fool</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/对抗样本（十一）Universal Perturbation/" title="对抗样本（十一）Universal Perturbation"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89Universal%20Perturbation/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">对抗样本（十一）Universal Perturbation</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'd3948be001a91411dfd9',
  clientSecret: 'ebddf2a2a5a039922fb373a8a8c0efcc439bf6ca',
  repo: 'BaiDingHub.github.io',
  owner: 'BaiDingHub',
  admin: ['BaiDingHub'],
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%EF%BC%88%E5%85%AB%EF%BC%89JSMA/cover.png?raw=true)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 白丁</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://jerryc.me/" target="_blank" rel="noopener">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js" ></script><script src="/js/utils.js" ></script><script src="/js/main.js" ></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/search/algolia.js"></script></body></html>