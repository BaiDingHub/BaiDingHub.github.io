<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>AI小知识系列(二) 训练过程Trick合集 | BaiDing's blog</title><meta name="description" content="AI小知识系列(二) 训练过程Trick合集"><meta name="keywords" content="AI小知识,训练Trick"><meta name="author" content="白丁"><meta name="copyright" content="白丁"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://raw.githubusercontent.com/BaiDingHub/Blog_images/master/BlogSource/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="crossorigin"/><link rel="preconnect" href="http://ta.qq.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="x-1ef6P_miWkq-RJn_fmjd3KYumrXANNXYzK1myaLf0"/><meta name="baidu-site-verification" content="guD6l44Chk"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="AI小知识系列(二) 训练过程Trick合集"><meta name="twitter:description" content="AI小知识系列(二) 训练过程Trick合集"><meta name="twitter:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/cover.png?raw=true"><meta property="og:type" content="article"><meta property="og:title" content="AI小知识系列(二) 训练过程Trick合集"><meta property="og:url" content="http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/"><meta property="og:site_name" content="BaiDing's blog"><meta property="og:description" content="AI小知识系列(二) 训练过程Trick合集"><meta property="og:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/cover.png?raw=true"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css" ><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/"><link rel="prev" title="AI小知识系列(三)  Pandas常用操作" href="http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%89)%20%20Pandas%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"><link rel="next" title="AI小知识系列(一) 面试小知识(1)" href="http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-162698439-1', 'auto');
ga('send', 'pageview');
</script><script src="https://tajs.qq.com/stats?sId=66540586" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"4JGH9NW4XG","apiKey":"41cdb6d9ec4d21196956524e9c985b36","indexName":"baiding","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/avatar.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/friend_404.gif?raw=true'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">93</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">60</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-写代码之前要做的事情"><span class="toc-text">1. 写代码之前要做的事情</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-设置端到端的训练评估框架"><span class="toc-text">2.设置端到端的训练评估框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1）固定随机种子"><span class="toc-text">1）固定随机种子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2）简单化"><span class="toc-text">2）简单化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3）绘制测试集损失"><span class="toc-text">3）绘制测试集损失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4）在初始阶段验证损失函数"><span class="toc-text">4）在初始阶段验证损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5）初始化"><span class="toc-text">5）初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6）人类基线"><span class="toc-text">6）人类基线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7）设置一个独立于输入的基线"><span class="toc-text">7）设置一个独立于输入的基线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8）过拟合一个batch"><span class="toc-text">8）过拟合一个batch</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9）验证减少训练损失"><span class="toc-text">9）验证减少训练损失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10）在训练模型前进行数据可视化"><span class="toc-text">10）在训练模型前进行数据可视化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11）可视化预测动态"><span class="toc-text">11）可视化预测动态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12）使用反向传播来获得依赖关系"><span class="toc-text">12）使用反向传播来获得依赖关系</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-挑选模型"><span class="toc-text">3.挑选模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1）挑选模型"><span class="toc-text">1）挑选模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2）Adam方法是安全的"><span class="toc-text">2）Adam方法是安全的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3）一次只复杂化一个"><span class="toc-text">3）一次只复杂化一个</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4）学习率设置"><span class="toc-text">4）学习率设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5）每轮训练数据乱序"><span class="toc-text">5）每轮训练数据乱序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6）batch-size选择"><span class="toc-text">6）batch_size选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7）学习率和batchsize的关系"><span class="toc-text">7）学习率和batchsize的关系</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-正则化"><span class="toc-text">4.正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1）获取更多数据"><span class="toc-text">1）获取更多数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2）数据扩增"><span class="toc-text">2）数据扩增</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3）有创意的扩增"><span class="toc-text">3）有创意的扩增</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4）预训练"><span class="toc-text">4）预训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5）跟监督学习死磕"><span class="toc-text">5）跟监督学习死磕</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6）输入低维一点"><span class="toc-text">6）输入低维一点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7）模型小一点"><span class="toc-text">7）模型小一点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8）减小批尺寸"><span class="toc-text">8）减小批尺寸</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9）Dropout"><span class="toc-text">9）Dropout</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10）权重衰减Weight-Decay"><span class="toc-text">10）权重衰减Weight Decay</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11）早停法Early-Stop"><span class="toc-text">11）早停法Early Stop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12）附加"><span class="toc-text">12）附加</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-调参"><span class="toc-text">5.调参</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1）随机网格搜索"><span class="toc-text">1）随机网格搜索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2）超参数优化"><span class="toc-text">2）超参数优化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-测试阶段"><span class="toc-text">6.测试阶段</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1）模型融合"><span class="toc-text">1）模型融合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2）TTA测试时增强"><span class="toc-text">2）TTA测试时增强</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考博客"><span class="toc-text">参考博客</span></a></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/cover.png?raw=true)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">BaiDing's blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">AI小知识系列(二) 训练过程Trick合集</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-04-03 11:12:05"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-04-03</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-12-02 11:11:09"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-12-02</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/">AI小知识</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">3.4k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 10 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/#post-comment"><span class="gitalk-comment-count comment-count"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><meta name="referrer" content="no-referrer"/>



<h1 id="1-写代码之前要做的事情"><a href="#1-写代码之前要做的事情" class="headerlink" title="1. 写代码之前要做的事情"></a>1. 写代码之前要做的事情</h1><p>训练神经网络前，别管代码，先从预处理数据集开始。我们先花几个小时的时间，了解<strong>数据的分布</strong>并找出其中的<strong>规律</strong>。</p>
<p>Andrej有一次在整理数据时发现了重复的样本，还有一次发现了图像和标签中的错误。所以先看一眼数据能避免我们走很多弯路。</p>
<p>由于神经网络实际上是数据集的压缩版本，因此您将能够查看网络（错误）预测并了解它们的来源。如果你的网络给你的预测看起来与你在数据中看到的内容不一致，那么就会有所收获。</p>
<p>一旦从数据中发现规律，可以编写一些代码对他们进行<strong>搜索、过滤、排序</strong>。把<strong>数据可视化</strong>能帮助我们<strong>发现异常值</strong>，而异常值总能揭示数据的质量或预处理中的一些错误。</p>
<h1 id="2-设置端到端的训练评估框架"><a href="#2-设置端到端的训练评估框架" class="headerlink" title="2.设置端到端的训练评估框架"></a>2.设置端到端的训练评估框架</h1><p>处理完数据集，接下来就能开始训练模型了吗？并不能！下一步是建立一个完整的训练+评估 框架。</p>
<p>在这个阶段，我们选择一个简单又不至于搞砸的模型，比如线性分类器、CNN，可视化损失。获得准确度等衡量模型的标准，用模型进行预测。</p>
<h3 id="1）固定随机种子"><a href="#1）固定随机种子" class="headerlink" title="1）固定随机种子"></a>1）固定随机种子</h3><p>使用固定的随机种子，来保证运行代码两次都获得相同的结果，消除差异因素。</p>
<h3 id="2）简单化"><a href="#2）简单化" class="headerlink" title="2）简单化"></a>2）简单化</h3><p>在此阶段不要有任何幻想，不要扩增数据。扩增数据后面会用到，但是在这里不要使用，现在引入只会导致错误。</p>
<h3 id="3）绘制测试集损失"><a href="#3）绘制测试集损失" class="headerlink" title="3）绘制测试集损失"></a>3）绘制测试集损失</h3><p>在绘制测试集损失时，对整个测试集进行评估，不要只绘制批次测试损失图像，然后用Tensorboard对它们进行平滑处理。</p>
<h3 id="4）在初始阶段验证损失函数"><a href="#4）在初始阶段验证损失函数" class="headerlink" title="4）在初始阶段验证损失函数"></a>4）在初始阶段验证损失函数</h3><p>验证函数是否从正确的损失值开始。例如，如果正确初始化最后一层，则应在softmax初始化时测量-log(1/n_classes)。</p>
<h3 id="5）初始化"><a href="#5）初始化" class="headerlink" title="5）初始化"></a>5）初始化</h3><p>正确初始化最后一层的权重。如果回归一些平均值为50的值，则将最终偏差初始化为50。如果有一个比例为1:10的不平衡数据集，请设置对数的偏差，使网络预测概率在初始化时为0.1。正确设置这些可以加速模型的收敛。</p>
<h3 id="6）人类基线"><a href="#6）人类基线" class="headerlink" title="6）人类基线"></a>6）人类基线</h3><p>监控除<strong>人为可解释</strong>和<strong>可检查</strong>的损失之外的指标。尽可能评估<strong>人的准确性</strong>并与之进行比较。或者对测试数据进行两次注释，并且对于每个示例，将一个注释视为预测，将第二个注释视为事实。</p>
<h3 id="7）设置一个独立于输入的基线"><a href="#7）设置一个独立于输入的基线" class="headerlink" title="7）设置一个独立于输入的基线"></a>7）设置一个独立于输入的基线</h3><p>最简单的方法是将所有输入设置为零，看看模型是否学会从输入中提取任何信息。</p>
<h3 id="8）过拟合一个batch"><a href="#8）过拟合一个batch" class="headerlink" title="8）过拟合一个batch"></a>8）过拟合一个batch</h3><p>增加了模型的容量并验证我们可以达到的最低损失。</p>
<h3 id="9）验证减少训练损失"><a href="#9）验证减少训练损失" class="headerlink" title="9）验证减少训练损失"></a>9）验证减少训练损失</h3><p>尝试稍微增加数据容量。</p>
<h3 id="10）在训练模型前进行数据可视化"><a href="#10）在训练模型前进行数据可视化" class="headerlink" title="10）在训练模型前进行数据可视化"></a>10）在训练模型前进行数据可视化</h3><p>将原始张量的数据和标签可视化，可以节省了调试次数，并揭示了数据预处理和数据扩增中的问题。</p>
<h3 id="11）可视化预测动态"><a href="#11）可视化预测动态" class="headerlink" title="11）可视化预测动态"></a>11）可视化预测动态</h3><p>在训练过程中对固定测试批次上的模型预测进行可视化。</p>
<h3 id="12）使用反向传播来获得依赖关系"><a href="#12）使用反向传播来获得依赖关系" class="headerlink" title="12）使用反向传播来获得依赖关系"></a>12）使用反向传播来获得依赖关系</h3><p>一个方法是将第i个样本的损失设置为1.0，运行反向传播一直到输入，并确保仅在第i个样本上有非零的梯度。</p>
<h1 id="3-挑选模型"><a href="#3-挑选模型" class="headerlink" title="3.挑选模型"></a>3.挑选模型</h1><p><strong>首先我们得有一个足够大的模型，它可以过拟合，减少训练集上的损失，然后适当地调整它，放弃一些训练集损失，改善在验证集上的损失）</strong></p>
<h3 id="1）挑选模型"><a href="#1）挑选模型" class="headerlink" title="1）挑选模型"></a>1）挑选模型</h3><p>为了获得较好的训练损失，我们需要为数据选择合适的架构。不要总想着一步到位。如果要做图像分类，只需复制粘贴ResNet-50，我们可以在稍后的过程中做一些自定义的事。</p>
<h3 id="2）Adam方法是安全的"><a href="#2）Adam方法是安全的" class="headerlink" title="2）Adam方法是安全的"></a>2）Adam方法是安全的</h3><p>在设定基线的早期阶段，使用学习率为3e-4的Adam 。根据经验，Adam对超参数更加宽容，包括不良的学习率。</p>
<h3 id="3）一次只复杂化一个"><a href="#3）一次只复杂化一个" class="headerlink" title="3）一次只复杂化一个"></a>3）一次只复杂化一个</h3><p>如果多个信号输入分类器，建议逐个输入，然后增加复杂性，确保预期的性能逐步提升，而不要一股脑儿全放进去。比如，尝试先插入较小的图像，然后再将它们放大。</p>
<h3 id="4）学习率设置"><a href="#4）学习率设置" class="headerlink" title="4）学习率设置"></a>4）学习率设置</h3><p>初始的学习率肯定是有一个最优值的，过大则导致模型不收敛，过小则导致模型收敛特别慢或者无法学习</p>
<p>可以采用<strong>搜索法</strong>，从小到大开始训练模型，记录损失的变化，比如从1e-5增大到1</p>
<p>也可以采用<strong>预设规则学习率变化法</strong>，见的策略包括fixed，step，exp，inv，multistep，poly，sigmoid等</p>
<p><div align = center>
<img src=https://img-blog.csdnimg.cn/20200115174513355.jpg width="60%">
<img src=https://img-blog.csdnimg.cn/20200115174533777.jpg width="60%">
</div><br>从结果来看：</p>
<ul>
<li>step，multistep方法的收敛效果最好，这也是我们平常用它们最多的原因。虽然学习率的变化是最离散的，但是并不影响模型收敛到比较好的结果。</li>
<li>其次是exp，poly。它们能取得与step，multistep相当的结果，也是因为学习率以比较好的速率下降，虽然变化更加平滑，但是结果也未必能胜过step和multistep方法，在这很多的研究中都得到过验证，离散的学习率变更策略不影响模型的学习。</li>
<li>inv和fixed的收敛结果最差。这是比较好解释的，因为fixed方法始终使用了较大的学习率，而inv方法的学习率下降过程太快。</li>
</ul>
<p>实验证明通过设置上下界，让学习率在其中进行变化，可以在模型迭代的后期更有利于克服因为学习率不够而无法跳出鞍点的情况。</p>
<h3 id="5）每轮训练数据乱序"><a href="#5）每轮训练数据乱序" class="headerlink" title="5）每轮训练数据乱序"></a>5）每轮训练数据乱序</h3><p>每轮数据迭代保持不同的顺序，避免模型每轮都对相同的数据进行计算。</p>
<h3 id="6）batch-size选择"><a href="#6）batch-size选择" class="headerlink" title="6）batch_size选择"></a>6）batch_size选择</h3><p>模型性能对batchsize虽然没有学习率那么敏感，但是在进一步提升模型性能时，batchsize就会成为一个非常关键的参数。</p>
<ul>
<li><strong>大的batchsize减少训练时间，提高稳定性</strong>，<strong>导致模型泛化能力下降</strong></li>
</ul>
<p>对于小数据量的模型，可以全量训练，这样能更准确的朝着极值所在的方向更新。但是对于大数据，全量训练将会导致内存溢出，因此需要选择一个较小的batch_size。如果这时选择batch_size为1，则此时为在线学习，每次修正方向为各自样本的梯度方向修正，难以达到收敛。batch_size增大，处理相同数据量的时间减少，但是达到相同精度的轮数增多。实际中可以逐步增大batch_size，随着batch_size增大，模型达到收敛，并且训练时间最为合适。</p>
<h3 id="7）学习率和batchsize的关系"><a href="#7）学习率和batchsize的关系" class="headerlink" title="7）学习率和batchsize的关系"></a>7）学习率和batchsize的关系</h3><p><strong>通常当我们增加batchsize为原来的N倍时，要保证经过同样的样本后更新的权重相等，按照线性缩放规则，学习率应该增加为原来的N倍[5]。但是如果要保证权重的方差不变，则学习率应该增加为原来的sqrt(N)倍[7]，目前这两种策略都被研究过，使用前者的明显居多。</strong></p>
<p>从两种常见的调整策略来看，学习率和batchsize都是同时增加的。学习率是一个非常敏感的因子，不可能太大，否则模型会不收敛。同样batchsize也会影响模型性能，那实际使用中都如何调整这两个参数呢？</p>
<p>研究表明，<strong>衰减学习率可以通过增加batchsize来实现类似的效果</strong>，这实际上从SGD的权重更新式子就可以看出来两者确实是等价的，文中通过充分的实验验证了这一点。</p>
<p>研究表明，<strong>对于一个固定的学习率，存在一个最优的batchsize能够最大化测试精度</strong>，这个batchsize和学习率以及训练集的大小正相关。</p>
<p>对此实际上是有两个建议：</p>
<ul>
<li>如果增加了学习率，那么batch size最好也跟着增加，这样收敛更稳定。</li>
<li>尽量使用大的学习率，因为很多研究都表明更大的学习率有利于提高泛化能力。如果真的要衰减，可以尝试其他办法，比如增加batch size，学习率对模型的收敛影响真的很大，慎重调整</li>
</ul>
<h1 id="4-正则化"><a href="#4-正则化" class="headerlink" title="4.正则化"></a>4.正则化</h1><p>理想的话，我们现在有一个大模型，在训练集上拟合好了。</p>
<p>现在，该正则化了。舍弃一点训练集上的准确率，可以换取验证集上的准确率。</p>
<h3 id="1）获取更多数据"><a href="#1）获取更多数据" class="headerlink" title="1）获取更多数据"></a>1）获取更多数据</h3><p>至今大家最偏爱的正则化方法，就是添加一些真实训练数据。</p>
<p>不要在一个小数据集花太大功夫，试图搞出大事情来。有精力去多收集点数据，这是唯一一个确保性能单调提升的方法。</p>
<h3 id="2）数据扩增"><a href="#2）数据扩增" class="headerlink" title="2）数据扩增"></a>2）数据扩增</h3><p>把数据集做大，除了继续收集数据之外，就是扩增了。旋转，翻转，拉伸，做扩增的时候可以野性一点。<br>可参考<a href="https://blog.csdn.net/StardustYu/article/details/103993505" target="_blank" rel="noopener">数据增强方法</a></p>
<h3 id="3）有创意的扩增"><a href="#3）有创意的扩增" class="headerlink" title="3）有创意的扩增"></a>3）有创意的扩增</h3><p>还有什么办法扩增数据集？比如域随机化 (Domain Randomization) ，模拟 (Simulation) ，巧妙的混合 (Hybrids) ，比如把数据插进场景里去。甚至可以用上GAN。</p>
<h3 id="4）预训练"><a href="#4）预训练" class="headerlink" title="4）预训练"></a>4）预训练</h3><p>当然，就算你手握充足的数据，直接用预训练模型也没坏处。</p>
<h3 id="5）跟监督学习死磕"><a href="#5）跟监督学习死磕" class="headerlink" title="5）跟监督学习死磕"></a>5）跟监督学习死磕</h3><p>不要对无监督预训练太过兴奋了。至少在视觉领域，无监督到现在也没有非常强大的成果。虽然，NLP领域有了BERT，有了会讲故事的GPT-2，但我们看到的效果很大程度上还是经过了人工挑选。</p>
<h3 id="6）输入低维一点"><a href="#6）输入低维一点" class="headerlink" title="6）输入低维一点"></a>6）输入低维一点</h3><p>把那些可能包含虚假信号的特征去掉，因为这些东西很可能造成过拟合，尤其是数据集不大的时候。</p>
<p>同理，如果低层细节不是那么重要的话，就输入小一点的图片，捕捉高层信息就好了。</p>
<h3 id="7）模型小一点"><a href="#7）模型小一点" class="headerlink" title="7）模型小一点"></a>7）模型小一点</h3><p>许多情况下，都可以给网络加上领域知识限制 (Domain Knowledge Constraints) ，来把模型变小。</p>
<p>比如，以前很流行在ImageNet的骨架上放全连接层，但现在这种操作已经被平均池化取代了，大大减少了参数。</p>
<h3 id="8）减小批尺寸"><a href="#8）减小批尺寸" class="headerlink" title="8）减小批尺寸"></a>8）减小批尺寸</h3><p>对批量归一化 (Batch Normalization) 这项操作来说，小批量可能带来更好的正则化效果 (Regularization) 。</p>
<h3 id="9）Dropout"><a href="#9）Dropout" class="headerlink" title="9）Dropout"></a>9）Dropout</h3><p>给卷积网络用dropout2d。不过使用需谨慎，因为这种操作似乎跟批量归一化不太合得来。</p>
<h3 id="10）权重衰减Weight-Decay"><a href="#10）权重衰减Weight-Decay" class="headerlink" title="10）权重衰减Weight Decay"></a>10）权重衰减Weight Decay</h3><p>增加权重衰减 (Weight Decay) 的惩罚力度。</p>
<p>L2正则化的目的就是为了让权重衰减到更小的值，在一定程度上减少模型过拟合的问题，所以权重衰减也叫L2正则化。</p>
<h3 id="11）早停法Early-Stop"><a href="#11）早停法Early-Stop" class="headerlink" title="11）早停法Early Stop"></a>11）早停法Early Stop</h3><p>不用一直一直训练，可以观察验证集的损失，在快要过拟合的时候，及时喊停。</p>
<h3 id="12）附加"><a href="#12）附加" class="headerlink" title="12）附加"></a>12）附加</h3><p>大模型很容易过拟合，几乎是必然，但早停的话，模型可以表现很好。</p>
<p>最后的最后，如果想要更加确信，自己训练出的网络，是个不错的分类器，就把第一层的权重可视化一下，看看边缘 (Edges) 美不美。</p>
<p>如果第一层的过滤器看起来像噪音，就需要再搞一搞了。同理，激活 (Activations) 有时候也会看出瑕疵来，那样就要研究一下哪里出了问题。</p>
<h1 id="5-调参"><a href="#5-调参" class="headerlink" title="5.调参"></a>5.调参</h1><h3 id="1）随机网格搜索"><a href="#1）随机网格搜索" class="headerlink" title="1）随机网格搜索"></a>1）随机网格搜索</h3><p>在同时调整多个超参数的情况下，网格搜索听起来是很诱人，可以把各种设定都包含进来。</p>
<p>但是要记住，随机搜索才是最好的。</p>
<p>直觉上说，这是因为网络通常对其中一些参数比较敏感，对其他参数不那么敏感。</p>
<p>如果参数a是有用的，参数b起不了什么作用，就应该对a取样更彻底一些，不要只在几个固定点上多次取样。</p>
<h3 id="2）超参数优化"><a href="#2）超参数优化" class="headerlink" title="2）超参数优化"></a>2）超参数优化</h3><p>世界上，有许多许多靓丽的贝叶斯超参数优化工具箱，很多小伙伴也给了这些工具好评。</p>
<p>但我个人的经验是，State-of-the-Art都是用实习生做出来的 (误) 。</p>
<h1 id="6-测试阶段"><a href="#6-测试阶段" class="headerlink" title="6.测试阶段"></a>6.测试阶段</h1><h3 id="1）模型融合"><a href="#1）模型融合" class="headerlink" title="1）模型融合"></a>1）模型融合</h3><h3 id="2）TTA测试时增强"><a href="#2）TTA测试时增强" class="headerlink" title="2）TTA测试时增强"></a>2）TTA测试时增强</h3><p>测试时将原始数据做<strong>不同形式的增强</strong>,然后取结果的<strong>平均值</strong>作为最终结果</p>
<p>提高了结果的稳定性和精准度.</p>
<h1 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h1><p><a href="https://zhuanlan.zhihu.com/p/64864995" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/64864995</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/63841572" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63841572</a></p>
<p><a href="http://karpathy.github.io/2019/04/25/recipe/" target="_blank" rel="noopener">http://karpathy.github.io/2019/04/25/recipe/</a></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">白丁</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/">http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://baidinghub.github.io" target="_blank">BaiDing's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/">AI小知识</a><a class="post-meta__tags" href="/tags/%E8%AE%AD%E7%BB%83Trick/">训练Trick</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDyIdOn/M/aXcGQOiSDVMqvN2gxDdiESHUfFuB2YMy48fvNN9SZOQUbVlGF4Pk6nDXIAir+br/EWuEnNLtgOCYMo/BTxl29gqS/QGHPiDaIQedzmLcuRZpfDuGit61N/b9pyktpZLagBgbl5Ox9mAgWQxXyhxYB092gyOXqrBULBeZUYQ+H7Eupha10QTQghHv4nLk+oYWo2UXEiijQpE3qMXT32G8v8k0KbRdd1hIFPyNEx6eZ6Buc2ZdbMtoutdGjvdnw5B1+dxgl1egESPChzcwCMxt3NW/3faQ5lsjRhQD4fRU+Ua/aqXe+0xg2+xr0BTjNr/JZIAaNiLuo71lH 1564026260@qq.com" async="async"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/wechat.png?raw=true" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/alipay.jpg?raw=true" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%89)%20%20Pandas%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"><img class="prev_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%89)%20%20Pandas%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">AI小知识系列(三)  Pandas常用操作</div></div></a></div><div class="next-post pull_right"><a href="/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/"><img class="next_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/cover.jpg?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">AI小知识系列(一) 面试小知识(1)</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/03/AI小知识系列(一)  面试小知识(1)/" title="AI小知识系列(一) 面试小知识(1)"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/cover.jpg?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">AI小知识系列(一) 面试小知识(1)</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/AI小知识系列(三)  Pandas常用操作/" title="AI小知识系列(三)  Pandas常用操作"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%89)%20%20Pandas%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">AI小知识系列(三)  Pandas常用操作</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/AI小知识系列(四)  Matplotlib常用操作/" title="AI小知识系列(四)  Matplotlib常用操作"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E5%9B%9B)%20%20Matplotlib%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">AI小知识系列(四)  Matplotlib常用操作</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/AI小知识系列(五) 面试小知识(2)/" title="AI小知识系列(五) 面试小知识(2)"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%94)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(2)/cover.jpg?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">AI小知识系列(五) 面试小知识(2)</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/具体的训练Trick/" title="具体的训练小技巧"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%85%B7%E4%BD%93%E7%9A%84%E8%AE%AD%E7%BB%83Trick/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">具体的训练小技巧</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'd3948be001a91411dfd9',
  clientSecret: 'ebddf2a2a5a039922fb373a8a8c0efcc439bf6ca',
  repo: 'BaiDingHub.github.io',
  owner: 'BaiDingHub',
  admin: ['BaiDingHub'],
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/cover.png?raw=true)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 白丁</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://jerryc.me/" target="_blank" rel="noopener">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js" ></script><script src="/js/utils.js" ></script><script src="/js/main.js" ></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/search/algolia.js"></script></body></html>