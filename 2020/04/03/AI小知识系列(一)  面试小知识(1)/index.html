<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>AI小知识系列(一) 面试小知识(1) | BaiDing's blog</title><meta name="description" content="AI小知识系列(一) 面试小知识(1)"><meta name="keywords" content="AI小知识,面试小知识"><meta name="author" content="白丁"><meta name="copyright" content="白丁"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://raw.githubusercontent.com/BaiDingHub/Blog_images/master/BlogSource/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="crossorigin"/><link rel="preconnect" href="http://ta.qq.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="x-1ef6P_miWkq-RJn_fmjd3KYumrXANNXYzK1myaLf0"/><meta name="baidu-site-verification" content="guD6l44Chk"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="AI小知识系列(一) 面试小知识(1)"><meta name="twitter:description" content="AI小知识系列(一) 面试小知识(1)"><meta name="twitter:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/cover.jpg?raw=true"><meta property="og:type" content="article"><meta property="og:title" content="AI小知识系列(一) 面试小知识(1)"><meta property="og:url" content="http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/"><meta property="og:site_name" content="BaiDing's blog"><meta property="og:description" content="AI小知识系列(一) 面试小知识(1)"><meta property="og:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/cover.jpg?raw=true"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css" ><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/"><link rel="prev" title="AI小知识系列(二) 训练过程Trick合集" href="http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/"><link rel="next" title="具体的训练小技巧" href="http://baidinghub.github.io/2020/04/03/%E5%85%B7%E4%BD%93%E7%9A%84%E8%AE%AD%E7%BB%83Trick/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-162698439-1', 'auto');
ga('send', 'pageview');
</script><script src="https://tajs.qq.com/stats?sId=66540586" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"4JGH9NW4XG","apiKey":"41cdb6d9ec4d21196956524e9c985b36","indexName":"baiding","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/avatar.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/friend_404.gif?raw=true'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">94</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">60</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#AI小知识系列—第一节"><span class="toc-text">AI小知识系列—第一节</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、神经网络反向传播公式推导"><span class="toc-text">1、神经网络反向传播公式推导</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、Batch-Normalization的反向传播过程"><span class="toc-text">2、Batch Normalization的反向传播过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、sigmoid的导数最大为0-25"><span class="toc-text">3、sigmoid的导数最大为0.25</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4、Softmax？Hardmax？"><span class="toc-text">4、Softmax？Hardmax？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5、bagging-vs-boosting"><span class="toc-text">5、bagging vs boosting</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6、Batch-normalization与Layer-normalization"><span class="toc-text">6、Batch-normalization与Layer-normalization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7、Normalization为什么会奏效"><span class="toc-text">7、Normalization为什么会奏效</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8、鲁棒性vs泛化能力"><span class="toc-text">8、鲁棒性vs泛化能力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9、numpy实现卷积的优化操作im2col"><span class="toc-text">9、numpy实现卷积的优化操作im2col</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/cover.jpg?raw=true)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">BaiDing's blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">AI小知识系列(一) 面试小知识(1)</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-04-03 11:11:05"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-04-03</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-12-02 11:11:09"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-12-02</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/">AI小知识</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">2.5k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 8 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/#post-comment"><span class="gitalk-comment-count comment-count"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><meta name="referrer" content="no-referrer"/>



<h1 id="AI小知识系列—第一节"><a href="#AI小知识系列—第一节" class="headerlink" title="AI小知识系列—第一节"></a>AI小知识系列—第一节</h1><h2 id="1、神经网络反向传播公式推导"><a href="#1、神经网络反向传播公式推导" class="headerlink" title="1、神经网络反向传播公式推导"></a>1、神经网络反向传播公式推导</h2><p> &emsp;  &emsp; 神经网络的反向传播是借助<strong>计算图</strong>和<strong>链式法则</strong>来进行的</p>
<p> &emsp;  &emsp; 以下面的函数为例，进行具体讲解：</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://img-blog.csdnimg.cn/20200306202227777.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70"  alt="在这里插入图片描述"></p>
<p> &emsp;  &emsp; 首先，我们先要声明，在这里$\ x_0,x_1$是这个函数的输入值，$\ w_0，w_1$是这个函数的参数，也就是反向传播需要进行更新的参数。 Z1~Z8是中间值，y是计算得到的结果。</p>
<script type="math/tex; mode=display">
根据链式法则，依次计算梯度。\\
y = \frac{1}{Z_1} 且Z_1=1.37\Rightarrow \frac{\partial y}{\partial Z_1}=-\frac{1}{1.37^2} \\
Z_1 = 1+Z_2 \Rightarrow \frac{\partial Z_1}{\partial Z_2} = 1\Rightarrow \frac{\partial y}{\partial Z_2} = \Rightarrow \frac{\partial y}{\partial Z_1} ·\frac{\partial Z_1}{\partial Z_2} = -\frac{1}{1.37^2} \\
\Downarrow \\
... \\
\Downarrow \\
\frac{\partial y}{\partial w_0} \ \ \frac{\partial y}{\partial w_1} \ \ \frac{\partial y}{\partial w_2} \\
\Downarrow \\
更新w_0,w_1,w_2\\
w_0 =w_0 -\eta \frac{\partial y}{\partial w_0} \\
w_1 =w_1 -\eta \frac{\partial y}{\partial w_1} \\
w_2 =w_2 -\eta \frac{\partial y}{\partial w_2} \\
\eta 为学习率 \\
到此反向传播完成。</script><h2 id="2、Batch-Normalization的反向传播过程"><a href="#2、Batch-Normalization的反向传播过程" class="headerlink" title="2、Batch Normalization的反向传播过程"></a>2、Batch Normalization的反向传播过程</h2><p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://img-blog.csdnimg.cn/20200306202142146.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70"  alt="在这里插入图片描述"><br><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://img-blog.csdnimg.cn/20200306202157672.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70"  alt="在这里插入图片描述"></p>
<h2 id="3、sigmoid的导数最大为0-25"><a href="#3、sigmoid的导数最大为0-25" class="headerlink" title="3、sigmoid的导数最大为0.25"></a>3、sigmoid的导数最大为0.25</h2><p> &emsp;  &emsp; 推导公式如下：</p>
<script type="math/tex; mode=display">
\sigma(x) = \frac{1}{1+e^{-x}} \\
\Downarrow \\
\sigma(x)' = \frac{e^{-x}}{(1+e^{-x})^2} \Rightarrow  \sigma(x)' = \frac{e^{-x}}{1+(e^{-x})^2 + 2*e^{-x}} \Rightarrow \sigma(x)' = \frac{1}{\frac{1}{e^{-x}}+e^{-x} + 2}\le \frac{1}{4}</script><p><br></p>
<h2 id="4、Softmax？Hardmax？"><a href="#4、Softmax？Hardmax？" class="headerlink" title="4、Softmax？Hardmax？"></a>4、Softmax？Hardmax？</h2><p> &emsp;  &emsp; 这次要解决的是，Softmax为何叫Softmax，它Soft在何处？</p>
<p> &emsp;  &emsp; 此处引用，<a href="https://zhuanlan.zhihu.com/p/34404607" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34404607</a></p>
<p> &emsp;  &emsp; 来看一下Softmax的表达式 </p>
<script type="math/tex; mode=display">
p_i = \frac{e^{x_i}}{\sum_j e^{x_j}}</script><p> &emsp;  &emsp; 与之相对应的表达式，我们可以称之为Hardmax</p>
<script type="math/tex; mode=display">
p_i = \frac{x_i}{\sum_j x_j}</script><p> &emsp;  &emsp; 那么，Softmax与Hardmax的区别如下：</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://img-blog.csdnimg.cn/20200306202250583.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70"  alt="在这里插入图片描述"></p>
<p> &emsp;  &emsp; Softmax是soft（软化）的max。在CNN的分类问题中，我们的ground truth是one-hot形式，下面以四分类为例，理想输出应该是（1，0，0，0），或者说（100%，0%，0%，0%），这就是我们想让CNN学到的终极目标。</p>
<p> &emsp;  &emsp; 相同输出特征情况，Softmax比Hardmax更容易达到终极目标one-hot形式，或者说，softmax降低了训练难度，使得多分类问题更容易收敛。</p>
<p> &emsp;  &emsp; Softmax鼓励真实目标类别输出比其他类别要大，但并不要求大很多。<strong>Softmax鼓励不同类别的特征分开，但并不鼓励特征分离很多</strong>，如上表（5，1，1，1）时loss就已经很小了，此时CNN接近收敛梯度不再下降。</p>
<p><br></p>
<h2 id="5、bagging-vs-boosting"><a href="#5、bagging-vs-boosting" class="headerlink" title="5、bagging vs boosting"></a>5、bagging vs boosting</h2><p> &emsp;  &emsp;  此处引用，<a href="https://blog.csdn.net/u013709270/article/details/72553282" target="_blank" rel="noopener">https://blog.csdn.net/u013709270/article/details/72553282</a></p>
<p> &emsp;  &emsp;  Bagging和Boosting都是将已有的分类或回归算法通过一定方式组合起来，形成一个性能更加强大的分类器。</p>
<p> &emsp;  &emsp; Bagging的算法过程如下：</p>
<p>1、 原始样本集中抽取训练集。每轮从原始样本集中使用自助法抽取n个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）。共进行k轮抽取，得到k个训练集。（k个训练集之间是相互独立的）</p>
<p>2、每次使用一个训练集得到一个模型，k个训练集共得到k个模型。（注：这里并没有具体的分类算法或回归方法，我们可以根据具体问题采用不同的分类或回归方法，如决策树、感知器等）</p>
<p>3、对分类问题：将上步得到的k个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。（所有模型的重要性相同）</p>
<p> &emsp;  &emsp; Boosting的两个核心问题：</p>
<p>1、在每一轮如何改变训练数据的权值或概率分布？<br> &emsp;  &emsp; 通过提高那些在前一轮被弱分类器分错样例的权值，减小前一轮分对样例的权值，来使得分类器对误分的数据有较好的效果。</p>
<p>2、通过什么方式来组合弱分类器？<br> &emsp;  &emsp; 通过加法模型将弱分类器进行线性组合，比如AdaBoost通过加权多数表决的方式，即增大错误率小的分类器的权值，同时减小错误率较大的分类器的权值。</p>
<p> &emsp;  &emsp; 两者的区别：</p>
<p>1）样本选择上：</p>
<p> &emsp;  &emsp; Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。</p>
<p> &emsp;  &emsp; Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。</p>
<p>2）样例权重：</p>
<p> &emsp;  &emsp; Bagging：使用均匀取样，每个样例的权重相等</p>
<p> &emsp;  &emsp; Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。</p>
<p>3）预测函数：</p>
<p> &emsp;  &emsp; Bagging：所有预测函数的权重相等。</p>
<p> &emsp;  &emsp; Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。</p>
<p>4）并行计算：</p>
<p> &emsp;  &emsp; Bagging：各个预测函数可以并行生成</p>
<p> &emsp;  &emsp; Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。</p>
<p>最后：</p>
<ol>
<li>Bagging + 决策树 = 随机森林</li>
<li>AdaBoost + 决策树 = 提升树</li>
<li>Gradient Boosting + 决策树 = GBDT</li>
</ol>
<p><br></p>
<h2 id="6、Batch-normalization与Layer-normalization"><a href="#6、Batch-normalization与Layer-normalization" class="headerlink" title="6、Batch-normalization与Layer-normalization"></a>6、Batch-normalization与Layer-normalization</h2><p> &emsp;  &emsp; Batch-normalization是在<strong>特征维度</strong>做normalization，是针对mini-batch所有数据的单个特征做的规范化。</p>
<p> &emsp;  &emsp; Layer-normalization是在<strong>样本维度</strong>做normalization，即对一个样本的所有特征做规范化。</p>
<p> &emsp;  &emsp; 此处引入对三种normalization的好的解释的文章<a href="https://zhuanlan.zhihu.com/p/33173246" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33173246</a></p>
<p><br></p>
<h2 id="7、Normalization为什么会奏效"><a href="#7、Normalization为什么会奏效" class="headerlink" title="7、Normalization为什么会奏效"></a>7、Normalization为什么会奏效</h2><ol>
<li>Normalization具有<strong>权重伸缩不变性</strong>（即对权重进行伸缩变换，规范化后的值是不变的），因此，这个性质就避免了反向传播因为权重过大或过小而造成的梯度问题，加速了收敛过程。同时这一属性也具有参数正则化的效果，避免了参数的大幅度震荡，提高了网络的泛化性能。</li>
<li>Normalization具有<strong>数据伸缩不变性</strong>，这一性质可以有效地减少梯度弥散，简化学习率的选择。</li>
<li>Normalization规范了每一层的数据输入，使得其分布一致，使得所有特征具有相同的均值和方差，这样这一层的神经元就不会因为上一层或下一层的神经元的剧烈变化而不稳定，也就加速了收敛。</li>
</ol>
<p><br></p>
<h2 id="8、鲁棒性vs泛化能力"><a href="#8、鲁棒性vs泛化能力" class="headerlink" title="8、鲁棒性vs泛化能力"></a>8、鲁棒性vs泛化能力</h2><p> &emsp;  &emsp; 鲁棒性字面上理解可以认为是健壮性，健壮性可以认为是更好，更加抗风险的</p>
<p> &emsp;  &emsp; 鲁棒性好代表该模型：</p>
<p> &emsp;  &emsp;  &emsp;  1.模型具有较高的精度或有效性，这也是对于机器学习中所有学习模型的基本要求；<br> &emsp;  &emsp;  &emsp;  2.对于模型假设出现的较小偏差，只能对算法性能产生较小的影响； 主要是：噪声（noise）<br> &emsp;  &emsp;  &emsp;  3.对于模型假设出现的较大偏差，不可对算法性能产生“灾难性”的影响；主要是：离群点（outlier）</p>
<p> &emsp;  &emsp; 在机器学习方法中，泛化能力通俗来讲就是指学习到的模型对未知数据的预测能力。在实际情况中，我们通常通过测试误差来评价学习方法的泛化能力。如果在不考虑数据量不足的情况下出现模型的泛化能力差，那么其原因基本为对损失函数的优化没有达到全局最优。</p>
<p><br></p>
<h2 id="9、numpy实现卷积的优化操作im2col"><a href="#9、numpy实现卷积的优化操作im2col" class="headerlink" title="9、numpy实现卷积的优化操作im2col"></a>9、numpy实现卷积的优化操作im2col</h2><p> &emsp;  &emsp; 我们假设卷积核的尺寸为$\ 2 <em> 2$ ，输入图像尺寸为$\ 3</em>3$ 。im2col做的事情就是对于卷积核每一次要处理的小窗，将其展开到新矩阵的一行（列），新矩阵的列（行）数，就是对于一副输入图像，卷积运算的次数（卷积核滑动的次数），如下图所示：</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://img-blog.csdnimg.cn/20200306202400978.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70"  alt="在这里插入图片描述"><br> &emsp;  &emsp; 以最右侧一列为例，卷积核为$\ 2*2$ ，所以新矩阵的列数就为4；步长为一，卷积核共滑动4次，行数就为4.再放一张图应该看得更清楚。</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://img-blog.csdnimg.cn/20200306202411384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70"  alt="在这里插入图片描述"><br> &emsp;  &emsp; 输入为$\ 4<em>4$ ，卷积核为$\ 3</em>3$，则新矩阵为$\ 9*4$ 。</p>
<p> &emsp;  &emsp; 看到这里我就产生了一个疑问：我们把一个卷积核对应的值展开，到底应该展开为行还是列呢？卷积核的滑动先行后列还是相反？区别在哪？<br> &emsp;  &emsp; 这其实主要取决于我们使用的框架访存的方式。计算机一次性读取相近的内存是最快的，尤其是当需要把数据送到GPU去计算的时候，这样可以节省访存的时间，以达到加速的目的。不同框架的访存机制不一样，所以会有行列相反这样的区别。在caffe框架下，im2col是将一个小窗的值展开为一行，而在matlab中则展开为列。所以说，行列的问题没有本质区别，目的都是为了在计算时读取连续的内存。<br> &emsp;  &emsp; 这也解释了我们为什么要通过这个变化来优化卷积。如果按照数学上的步骤做卷积读取内存是不连续的，这样就会增加时间成本。同时我们注意到做卷积对应元素相乘再相加的做法跟向量内积很相似，所以通过im2col将矩阵卷积转化为矩阵乘法来实现。<br>im2col的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">im2col</span><span class="params">(image, ksize, stride)</span>:</span></span><br><span class="line">    <span class="comment"># image is a 4d tensor([batchsize, width ,height, channel])</span></span><br><span class="line">    image_col = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, image.shape[<span class="number">1</span>] - ksize + <span class="number">1</span>, stride):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, image.shape[<span class="number">2</span>] - ksize + <span class="number">1</span>, stride):</span><br><span class="line">            col = image[:, i:i + ksize, j:j + ksize, :].reshape([<span class="number">-1</span>])</span><br><span class="line">            image_col.append(col)</span><br><span class="line">    image_col = np.array(image_col)</span><br><span class="line">    <span class="keyword">return</span> image_col</span><br></pre></td></tr></table></figure>
<p>此处引用文章<a href="https://blog.csdn.net/dwyane12138/article/details/78449898" target="_blank" rel="noopener">https://blog.csdn.net/dwyane12138/article/details/78449898</a></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">白丁</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/">http://baidinghub.github.io/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://baidinghub.github.io" target="_blank">BaiDing's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/">AI小知识</a><a class="post-meta__tags" href="/tags/%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86/">面试小知识</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDyIdOn/M/aXcGQOiSDVMqvN2gxDdiESHUfFuB2YMy48fvNN9SZOQUbVlGF4Pk6nDXIAir+br/EWuEnNLtgOCYMo/BTxl29gqS/QGHPiDaIQedzmLcuRZpfDuGit61N/b9pyktpZLagBgbl5Ox9mAgWQxXyhxYB092gyOXqrBULBeZUYQ+H7Eupha10QTQghHv4nLk+oYWo2UXEiijQpE3qMXT32G8v8k0KbRdd1hIFPyNEx6eZ6Buc2ZdbMtoutdGjvdnw5B1+dxgl1egESPChzcwCMxt3NW/3faQ5lsjRhQD4fRU+Ua/aqXe+0xg2+xr0BTjNr/JZIAaNiLuo71lH 1564026260@qq.com" async="async"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/wechat.png?raw=true" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/alipay.jpg?raw=true" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/04/03/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/"><img class="prev_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/cover.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">AI小知识系列(二) 训练过程Trick合集</div></div></a></div><div class="next-post pull_right"><a href="/2020/04/03/%E5%85%B7%E4%BD%93%E7%9A%84%E8%AE%AD%E7%BB%83Trick/"><img class="next_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%85%B7%E4%BD%93%E7%9A%84%E8%AE%AD%E7%BB%83Trick/cover.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">具体的训练小技巧</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/03/AI小知识系列(五) 面试小知识(2)/" title="AI小知识系列(五) 面试小知识(2)"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%94)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(2)/cover.jpg?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">AI小知识系列(五) 面试小知识(2)</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/AI小知识系列(二) 训练过程Trick合集/" title="AI小知识系列(二) 训练过程Trick合集"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%BA%8C)%20%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8BTrick%E5%90%88%E9%9B%86/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">AI小知识系列(二) 训练过程Trick合集</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/AI小知识系列(三)  Pandas常用操作/" title="AI小知识系列(三)  Pandas常用操作"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%89)%20%20Pandas%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">AI小知识系列(三)  Pandas常用操作</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/AI小知识系列(四)  Matplotlib常用操作/" title="AI小知识系列(四)  Matplotlib常用操作"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E5%9B%9B)%20%20Matplotlib%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/cover.jpg?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">AI小知识系列(四)  Matplotlib常用操作</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/具体的训练Trick/" title="具体的训练小技巧"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%85%B7%E4%BD%93%E7%9A%84%E8%AE%AD%E7%BB%83Trick/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">具体的训练小技巧</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'd3948be001a91411dfd9',
  clientSecret: 'ebddf2a2a5a039922fb373a8a8c0efcc439bf6ca',
  repo: 'BaiDingHub.github.io',
  owner: 'BaiDingHub',
  admin: ['BaiDingHub'],
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AI%E5%B0%8F%E7%9F%A5%E8%AF%86/AI%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%80)%20%20%E9%9D%A2%E8%AF%95%E5%B0%8F%E7%9F%A5%E8%AF%86(1)/cover.jpg?raw=true)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 白丁</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://jerryc.me/" target="_blank" rel="noopener">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js" ></script><script src="/js/utils.js" ></script><script src="/js/main.js" ></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/search/algolia.js"></script></body></html>