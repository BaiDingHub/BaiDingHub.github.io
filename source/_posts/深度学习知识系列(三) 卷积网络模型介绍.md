---
title: 深度学习知识系列(三) 卷积网络模型介绍
date: 2020-04-03 11:23:05
tags:
 - [深度基础知识]
 - [卷积网络模型]
categories: 
 - [深度学习,深度基础知识系列]
keyword: "深度学习,深度基础知识系列,卷积网络模型"
description: "深度学习知识系列(三) 卷积网络模型介绍"
cover: https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97(%E4%B8%89)%20%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/cover.png?raw=true
---

<meta name="referrer" content="no-referrer"/>

# 1、LeNet

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165817833.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center =500x)



 &emsp; &emsp; LeNet 诞生于 1994 年，是最早的卷积神经网络之一，并且推动了深度学习领域的发展。这篇文章对之后的发展具有开创意义。在那个没有GPU加速的年代，LeNet设计简单，这也就使其处理复杂数据的能力有限。

<br>

# 2、AlexNet

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165829561.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center =600x)



 &emsp; &emsp; 12年AlexNet诞生，并在ImageNet上取得了第一名的成绩，在测试集上的top-1和top-5错误率为37.5%和17.0%。

 &emsp; &emsp; 在当时，算力仍然不足。作者利用了**两个GPU联合训练**。也就是将一个模型的参数分布在了两个GPU上，训练出来的AlexNet。这是卷积网络辉煌的开始。

 &emsp; &emsp; 使用了**ReLU函数**，一定程度上减小了梯度弥散问题，同时加快了训练速度。

 &emsp; &emsp; **重叠池化（Overlapping Pooling）**，在相邻池化窗口之间有重叠部分，这使他们的top-1和top-5错误率分别降低了0.4%和0.3%。

 &emsp; &emsp; 使用了**0.5的dropout**、**batch size设为128**、**Momentum设为0.9**、**学习率0.1**、L**2 weight decay为5e-4**，共使用了7层CNN

<br>

# 3、VGG

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165838893.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center =400x)

 &emsp; &emsp; 14年VGG诞生，在ImageNet上取得了第二名的成绩

 &emsp; &emsp; VGG的思想，使**纵向加深网络，显著的增加了网络层数，16层CNN** 。

 &emsp; &emsp; 大大的减少了kernel size，**大量的使用3x3的卷积核**，因为多个小的滤波器的组合与一个大的滤波器的感受野差不多，但能够大大的减少训练参数

 &emsp; &emsp; 但VGG过大的网络造成了需要极其庞大的训练资源（全连接层参数过多），训练较慢，而且整个模型极大，有144M。

<br>

# 4、GoogLeNet

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165850700.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center =500x)

 &emsp; &emsp; 14年GoogLeNet诞生，在ImageNet上取得了第一名的成绩

 &emsp; &emsp; 与VGG不同，GoogLeNet使**横向的加深网络**，提出了**Inception结构**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165855724.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center =400x)

 &emsp; &emsp; 在Inception模块中

-  提供更“宽”的网络结构（1x1 3x3 5x5 ），使网络可自由选择更好的特征，maxpooling则是去掉上一层卷积下来的冗余信息。
- 通过**1x1的卷积核**，实现降维和升维，达到减少参数的目的，其中，降维是利用了1x1的卷积核可线性组合不同通道上的特征的特性。（这与稀疏网络结构也密切相关）

 &emsp; &emsp; GoogLeNet通过使用Inception结构，极大的减少了模型的大小。

<br>

# 5、ResNet

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165903661.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center =500x)

 &emsp; &emsp; 15年ResNet诞生，在ImageNet上取得了第一名的成绩

 &emsp; &emsp; ResNet通过实验得到，像VGG那样简单的堆叠不能够提高网络的性能，于是提出了**残差模块**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165914612.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center =400x)

 &emsp; &emsp; 当网络不断加深时，梯度爆炸与梯度弥散的问题将会出现，而残差模块的引入，通过将以后层的梯度与前面的层相联系，而解决了这一问题，这使得网络的训练变得很容易。

 &emsp; &emsp; 有了残差模块之后，一般网络的层数越高，性能越好，当然训练也会变得越难。

 &emsp; &emsp; 残差模块的作用就是**feature重用**，将前面层的简单的feature与后面层的高维的feature进行联系。

 &emsp; &emsp; ResNet的内存占用也很小，Res-164只有1.7M。

 &emsp; &emsp; ResNet也是在之后学习生涯中最常用的backbone之一。

<br>

# 6、ResNeXt

 &emsp; &emsp; 16年ResNeXt诞生，其是ResNet与GoogLeNet的变体。即在Inception模块上加入了残差模块。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020030816592143.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center =400x)

<br>

# 7、DenseNet

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165929214.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center)

 &emsp; &emsp; 17年的DenseNet时ResNet的拓展，将残差模块拓展到了Dense block，即一个Dense模块的每一部分都进行连接。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165933495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N0YXJkdXN0WXU=,size_16,color_FFFFFF,t_70#pic_center =400x)

 &emsp; &emsp; 这一举看似粗暴，实则带来不少好处。从 feature 来考虑，每一层 feature 被用到时，都可以被看作做了新的 normalization。DenseNet的模型会更加robust。

 &emsp; &emsp; 天底下没有免费的午餐，DenseNet这一操作也是其模型变得机器庞大，Dnese-100-24有27.2M。

<br>

# 8、SeNet

 &emsp; &emsp; 17年SeNet诞生，在ImageNet上取得了第一名的成绩

 &emsp; &emsp; 其创新点在于其**SE block** 。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308165942413.jpg#pic_center =500x)

 &emsp; &emsp; 图中的Ftr是传统的卷积结构，X和U是Ftr的输入（C'xH'xW'）和输出（CxHxW），这些都是以往结构中已存在的。SENet增加的部分是U后的结构：对U先做一个Global Average Pooling（图中的Fsq(.)，作者称为Squeeze过程），输出的1x1xC数据再经过两级全连接（图中的Fex(.)，作者称为Excitation过程），最后用sigmoid（论文中的self-gating mechanism）限制到[0，1]的范围，把这个值作为scale乘到U的C个通道上， 作为下一级的输入数据。这种结构的原理是想通过控制scale的大小，**把重要的特征增强，不重要的特征减弱，从而让提取的特征指向性更强。**

