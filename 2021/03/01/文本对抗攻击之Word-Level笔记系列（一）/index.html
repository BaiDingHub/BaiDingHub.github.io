<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>文本对抗攻击之Word-Level笔记系列（一） | BaiDing's blog</title><meta name="description" content="文本对抗攻击之Word-Level笔记系列（一）"><meta name="keywords" content="文本对抗攻击,Word-Level,论文笔记"><meta name="author" content="白丁"><meta name="copyright" content="白丁"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://raw.githubusercontent.com/BaiDingHub/Blog_images/master/BlogSource/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="crossorigin"/><link rel="preconnect" href="http://ta.qq.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="x-1ef6P_miWkq-RJn_fmjd3KYumrXANNXYzK1myaLf0"/><meta name="baidu-site-verification" content="guD6l44Chk"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="文本对抗攻击之Word-Level笔记系列（一）"><meta name="twitter:description" content="文本对抗攻击之Word-Level笔记系列（一）"><meta name="twitter:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/cover.png?raw=true"><meta property="og:type" content="article"><meta property="og:title" content="文本对抗攻击之Word-Level笔记系列（一）"><meta property="og:url" content="http://baidinghub.github.io/2021/03/01/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/"><meta property="og:site_name" content="BaiDing's blog"><meta property="og:description" content="文本对抗攻击之Word-Level笔记系列（一）"><meta property="og:image" content="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/cover.png?raw=true"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css" ><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://baidinghub.github.io/2021/03/01/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/"><link rel="prev" title="文本对抗攻击之Word-Level笔记系列（二）" href="http://baidinghub.github.io/2021/03/01/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89/"><link rel="next" title="NLP词向量篇（八）ALBERT" href="http://baidinghub.github.io/2020/09/23/NLP%E8%AF%8D%E5%90%91%E9%87%8F%E7%AF%87%EF%BC%88%E5%85%AB%EF%BC%89ALBERT/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-162698439-1', 'auto');
ga('send', 'pageview');
</script><script src="https://tajs.qq.com/stats?sId=66540586" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"4JGH9NW4XG","apiKey":"41cdb6d9ec4d21196956524e9c985b36","indexName":"baiding","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/avatar.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/friend_404.gif?raw=true'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">94</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">60</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、Crafting-adversarial-input-sequences-for-recurrent-neural-networks"><span class="toc-text">一、Crafting adversarial input sequences for recurrent neural networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Paper-Information"><span class="toc-text">1. Paper Information</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Motivation"><span class="toc-text">2. Motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Main-Arguments"><span class="toc-text">3. Main Arguments</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Framework"><span class="toc-text">4. Framework</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Adversarial-Samples-and-Sequences"><span class="toc-text">4.1 Adversarial Samples and Sequences</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-1-Adversarial-Samples"><span class="toc-text">4.1.1 Adversarial Samples</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-2-Adversarial-Sequences"><span class="toc-text">4.1.2 Adversarial Sequences</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Using-FGSM"><span class="toc-text">4.2 Using FGSM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Using-Forward-Derivative"><span class="toc-text">4.3 Using Forward Derivative</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Result"><span class="toc-text">5.Result</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Setup"><span class="toc-text">5.1 Setup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Recurrent-Neural-Networks-with-Categorical-Output"><span class="toc-text">5.2 Recurrent Neural Networks with Categorical Output</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-Recurrent-Neural-Networks-with-Sequential-Output"><span class="toc-text">5.3 Recurrent Neural Networks with Sequential Output</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Argument"><span class="toc-text">6. Argument</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Further-research"><span class="toc-text">7. Further research</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二、Towards-Crafting-Text-Adversarial-Samples"><span class="toc-text">二、Towards Crafting Text Adversarial Samples.</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Paper-Information-1"><span class="toc-text">1. Paper Information</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Motivation-1"><span class="toc-text">2. Motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Main-Arguments-1"><span class="toc-text">3. Main Arguments</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Framework-1"><span class="toc-text">4. Framework</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Calculate-contribution-of-each-word"><span class="toc-text">4.1 Calculate contribution of each word</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Build-candidate-pool-P-for-each-word-in-sample-text"><span class="toc-text">4.2 Build candidate pool P for each word in sample text</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-1-Synonyms-and-typos"><span class="toc-text">4.2.1 Synonyms and typos</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-2-Genre-specific-keywords"><span class="toc-text">4.2.2 Genre specific keywords</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Crafting-the-adversarial-sample"><span class="toc-text">4.3 Crafting the adversarial sample</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-1-Removal-of-words"><span class="toc-text">4.3.1 Removal of words</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2-Addition-of-words"><span class="toc-text">4.3.2 Addition of words</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-3-Replacement-of-word"><span class="toc-text">4.3.3 Replacement of word</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Result-1"><span class="toc-text">5.Result</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Performance"><span class="toc-text">5.1 Performance</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Argument-1"><span class="toc-text">6. Argument</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Further-research-1"><span class="toc-text">7. Further research</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#三、Deep-Text-Classification-Can-be-Fooled"><span class="toc-text">三、Deep Text Classification Can be Fooled</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Paper-Information-2"><span class="toc-text">1. Paper Information</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Motivation-2"><span class="toc-text">2. Motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Main-Arguments-2"><span class="toc-text">3. Main Arguments</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Framework-2"><span class="toc-text">4. Framework</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-White-box-Attack"><span class="toc-text">4.1 White-box Attack</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-1-Identifying-Classification-important-Items"><span class="toc-text">4.1.1 Identifying Classification-important Items</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-2-Attacking-Character-level-DNN"><span class="toc-text">4.1.2 Attacking Character-level DNN</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#4-1-2-1-Insertion-Strategy"><span class="toc-text">4.1.2.1 Insertion Strategy</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-1-2-2-Modification-Strategy"><span class="toc-text">4.1.2.2 Modification Strategy</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-1-2-3-Removal-Strategy"><span class="toc-text">4.1.2.3 Removal Strategy</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-3-Attacking-Word-level-DNN"><span class="toc-text">4.1.3 Attacking Word-level DNN</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Black-box-Attack"><span class="toc-text">4.2 Black-box Attack</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Result-2"><span class="toc-text">5.Result</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Argument-2"><span class="toc-text">6. Argument</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Further-research-2"><span class="toc-text">7. Further research</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/cover.png?raw=true)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">BaiDing's blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于作者</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">文本对抗攻击之Word-Level笔记系列（一）</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-03-01 05:20:00"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2021-03-01</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-03-16 15:20:23"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2021-03-16</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/">文本对抗</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">4.5k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 15 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2021/03/01/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/#post-comment"><span class="gitalk-comment-count comment-count"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><meta name="referrer" content="no-referrer"/>



<h1 id="一、Crafting-adversarial-input-sequences-for-recurrent-neural-networks"><a href="#一、Crafting-adversarial-input-sequences-for-recurrent-neural-networks" class="headerlink" title="一、Crafting adversarial input sequences for recurrent neural networks"></a>一、Crafting adversarial input sequences for recurrent neural networks</h1><h2 id="1-Paper-Information"><a href="#1-Paper-Information" class="headerlink" title="1. Paper Information"></a>1. Paper Information</h2><blockquote>
<p>时间：2016年</p>
<p>关键词：Adversarial Attack，White-box</p>
<p>论文位置：<a href="https://arxiv.org/pdf/1604.08275.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1604.08275.pdf</a></p>
<p>引用：Papernot N, McDaniel P, Swami A, et al. Crafting adversarial input sequences for recurrent neural networks[C]//MILCOM 2016-2016 IEEE Military Communications Conference. IEEE, 2016: 49-54.</p>
</blockquote>
<h2 id="2-Motivation"><a href="#2-Motivation" class="headerlink" title="2. Motivation"></a>2. Motivation</h2><p> &emsp;&emsp; 此前，大多数的对抗样本大多处理CV的分类任务，在本篇论文中，我们将把对抗样本用于RNN网络中，用来处理序列数据。</p>
<h2 id="3-Main-Arguments"><a href="#3-Main-Arguments" class="headerlink" title="3. Main Arguments"></a>3. Main Arguments</h2><p> &emsp;&emsp; 本篇论文形式化了序列数据下的对抗样本优化问题，针对RNN的特点，我们采用前向导数的构造算法。这包括演示如何计算循环计算图的前导数。我们研究了从模型的预处理输入到原始输入的对抗性扰动。我们使用RNN模型进行分类和顺序预测来评估我们的攻击方法的性能。平均而言，在71个单词的影评中改变9个单词足以让我们的分类RNN在对影评进行情绪分析时做出100%错误的类预测。</p>
<h2 id="4-Framework"><a href="#4-Framework" class="headerlink" title="4. Framework"></a>4. Framework</h2><h3 id="4-1-Adversarial-Samples-and-Sequences"><a href="#4-1-Adversarial-Samples-and-Sequences" class="headerlink" title="4.1 Adversarial Samples and Sequences"></a>4.1 Adversarial Samples and Sequences</h3><h4 id="4-1-1-Adversarial-Samples"><a href="#4-1-1-Adversarial-Samples" class="headerlink" title="4.1.1 Adversarial Samples"></a>4.1.1 Adversarial Samples</h4><p> &emsp;&emsp; 当输入是序列，但是输出是类别时，要解决的问题是：</p>
<script type="math/tex; mode=display">
\vec{x^*} = \vec{x} + \delta_{\vec{x}} = \vec{x} + \min ||\vec{z}|| \ s.t. \ f(\vec{x} + \vec{z}) \ne f(\vec{x}) \tag{3}</script><h4 id="4-1-2-Adversarial-Sequences"><a href="#4-1-2-Adversarial-Sequences" class="headerlink" title="4.1.2 Adversarial Sequences"></a>4.1.2 Adversarial Sequences</h4><p> &emsp;&emsp; 当输入和输出都是序列时：</p>
<script type="math/tex; mode=display">
\vec{x^*} = \vec{x} + \delta_{\vec{x}} = \vec{x} + \min ||\vec{z}|| \ s.t. ||\ f(\vec{x} + \vec{z})- \vec{y^*}|| \le \Delta \tag{4}</script><h3 id="4-2-Using-FGSM"><a href="#4-2-Using-FGSM" class="headerlink" title="4.2 Using FGSM"></a>4.2 Using FGSM</h3><p> &emsp;&emsp; 使用FGSM解决问题（3）：</p>
<script type="math/tex; mode=display">
\vec{x^*} = \vec{x} + \delta_{\vec{x}} = \vec{x^*} = \vec{x} + \epsilon\ \text{sign}(\nabla_{\vec{x}} c(f,\vec{x}, \vec{y}))</script><p> &emsp;&emsp; 其中，$\ c$ 表示损失函数</p>
<h3 id="4-3-Using-Forward-Derivative"><a href="#4-3-Using-Forward-Derivative" class="headerlink" title="4.3 Using Forward Derivative"></a>4.3 Using Forward Derivative</h3><p> &emsp;&emsp; 前向导数是生成对抗样本的另一种方法，前向导数可以用模型的Jacobian矩阵定义：</p>
<script type="math/tex; mode=display">
J_f[i,j] = \frac{\partial f_j}{\partial x_i}</script><p> &emsp;&emsp; 其中，$\ x_i$ 表示输入的第i个元素，$\ f_j$ 表示输出的第j个元素。它精确的估计了输出元素$\ f_j$ 对输入元素$\ x_i$ 的敏感性。</p>
<p> &emsp;&emsp; 当计算图存在循环时，我们并不是那么容易计算前向导数，比如RNN模型。因此，作者使用了<strong>计算图展开</strong>技术。</p>
<p> &emsp;&emsp; 那么，对于RNN来说，第t个时间步的输出是：</p>
<script type="math/tex; mode=display">
h^{(t)}(\vec{x}) = \phi(h^{(t-1)}(\vec{x}), \vec{x}, \vec{w})</script><p> &emsp;&emsp; 将上述式子展开，我们得到：</p>
<script type="math/tex; mode=display">
h^{(t)}(\vec{x}) = \phi(\phi(\dots\phi(h^{(t-1)}(\vec{x}), \vec{x}, \vec{w}),\dots  \vec{x}, \vec{w}), \vec{x}, \vec{w})</script><p> &emsp;&emsp; 我们通过展开他的递归分量，我们就使得RNN的计算图变成了无环的。这样，我们就可以计算前向梯度：</p>
<script type="math/tex; mode=display">
J_f[i,j] = \frac{\partial f^{(j)}}{\partial x^{(i)}}</script><p> &emsp;&emsp; 其中，$\ x^{(i)}$ 表示第i步的输入序列，$\ y^{(j)}$ 表示第j步的输出序列。使用链式法则展开就可以计算。</p>
<p> &emsp;&emsp; 因此，我们使用前向导数，我们既可以解决问题（3）也可以解决问题（4），即分类和序列问题。</p>
<p> &emsp;&emsp; 在解决序列问题时，我们逐级的考虑输出序列。Jacobian矩阵的每一列对应于第j步的输出序列，如果第i步的输入序列在这一列有较高的绝对值，而其他列较小，说明该步在第j步的输出有很大影响。因此，我们只需要按照$\ \text{sign}(J_f[i,j]) \times \text{sign}(\vec{y_j^<em>})$ 这个方向去修改第i步的输入，我们就能够得到我们想要的输出（即分类为$\ \vec{y_j^</em>}$ ）</p>
<h2 id="5-Result"><a href="#5-Result" class="headerlink" title="5.Result"></a>5.Result</h2><h3 id="5-1-Setup"><a href="#5-1-Setup" class="headerlink" title="5.1 Setup"></a>5.1 Setup</h3><p> &emsp;&emsp; 作者使用了两种模型，一种是用于分类的RNN，用来分类影评的情感色彩，二分类任务，我们通过修改影评的词来误导分类器。另一种是用于序列输入和序列输出的RNN，基于雅可比矩阵的攻击通过识别每个输入序列步骤的贡献来改变模型的输出。</p>
<h3 id="5-2-Recurrent-Neural-Networks-with-Categorical-Output"><a href="#5-2-Recurrent-Neural-Networks-with-Categorical-Output" class="headerlink" title="5.2 Recurrent Neural Networks with Categorical Output"></a>5.2 Recurrent Neural Networks with Categorical Output</h3><p> &emsp;&emsp; 采用了RNN影评分类器，我们在该模型上实现了100%的攻击成功率，在2000条影评（平均有71个词）上，平均只需要修改9.18个词。</p>
<p> &emsp;&emsp; 作者的分类模型为：四层模型，输入层、LSTM层、Mean Pooling层和Softmax层：</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/1.png?raw=true"  alt="1"></p>
<p> &emsp;&emsp; 数据集包含2000条训练影评，500条测试影评。影评字典包含有10000个字。词向量的维度是128。模型在该数据集上实现了100%的训练准确率和78.21的测试准确率。</p>
<p> &emsp;&emsp; 在攻击时，我们需要使用字典中的单词来修改输入句子，使得他的预测标签发生变化。首先，我们计算关于输入的词向量的Jacobian矩阵，即$\ J<em>f(\vec{x})[i,j] = \frac{\partial h_j}{\partial x_i}$ ，这为我们提供了，输入词向量与池化层输出的变化之间的映射关系。那么，对于输入序列的每个单词i，我们就可以根据Jacobian矩阵的值$\ \text{sign}(J_f(\vec{x})[i,f(\vec{x})]),其中f(\vec{x}) = \arg \max</em>{0,1}(p_j)$  得到每个词向量需要去扰动的方向。</p>
<p> &emsp;&emsp; 而与CV中不同的是，我们面临了一个困难，即：<strong>我们的词向量是有限的，即只有有限个词向量对应有词，因此，我们无法使得对抗样本中的词向量是任意的向量。</strong> 为了解决这个问题，我们使用了下面的算法</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/2.png?raw=true"  alt="2"></p>
<p> &emsp;&emsp; 我们从词典中，找到与$\ \text{sign}(J_f(\vec{x}[i,y]))$ 方向上最接近的词向量$\ \vec{z}$ 。通过这种方法，我们就找到了最接近Jacobian矩阵所表示的方向，也就是对模型预测影响最大的词向量。通过迭代的寻找，我们就可以得到我们的对抗样本。</p>
<h3 id="5-3-Recurrent-Neural-Networks-with-Sequential-Output"><a href="#5-3-Recurrent-Neural-Networks-with-Sequential-Output" class="headerlink" title="5.3 Recurrent Neural Networks with Sequential Output"></a>5.3 Recurrent Neural Networks with Sequential Output</h3><p> &emsp;&emsp; 在该实验中，作者采用的是合成数据。我们对100个生成的输入和输出序列对进行训练。每步输入5个值，每步输出3个值。两个序列都有10步长。</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/3.png?raw=true"  alt="3"></p>
<p> &emsp;&emsp; 作者进行了简介，并没有详细描述。</p>
<h2 id="6-Argument"><a href="#6-Argument" class="headerlink" title="6. Argument"></a>6. Argument</h2><p> &emsp;&emsp; 该篇论文是第一篇文本领域的对抗样本研究，研究了在分类和序列输出情况下的攻击，但没有对序列输出进行详细描述，而且模型和数据集并没有那么正式。本文的方法属于白盒攻击。本文也告诉了我们，RNN模型也存在对抗样本的问题。</p>
<h2 id="7-Further-research"><a href="#7-Further-research" class="headerlink" title="7. Further research"></a>7. Further research</h2><p> &emsp;&emsp; 未来的工作还应该解决对抗性序列的语法问题，以提高它们的<strong>语义意义</strong>，并确保它们对人类是不可区分的。同时，应该要考虑<strong>黑盒攻击</strong>以及<strong>迁移性问题</strong>。</p>
<h1 id="二、Towards-Crafting-Text-Adversarial-Samples"><a href="#二、Towards-Crafting-Text-Adversarial-Samples" class="headerlink" title="二、Towards Crafting Text Adversarial Samples."></a>二、Towards Crafting Text Adversarial Samples.</h1><h2 id="1-Paper-Information-1"><a href="#1-Paper-Information-1" class="headerlink" title="1. Paper Information"></a>1. Paper Information</h2><blockquote>
<p>时间：2017年</p>
<p>关键词：Adversarial Attack，White-box， Genre， Word-Level</p>
<p>论文位置：<a href="https://arxiv.org/pdf/1707.02812.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1707.02812.pdf</a></p>
<p>引用：Samanta S, Mehta S. Towards crafting text adversarial samples[J]. arXiv preprint arXiv:1707.02812, 2017.</p>
</blockquote>
<h2 id="2-Motivation-1"><a href="#2-Motivation-1" class="headerlink" title="2. Motivation"></a>2. Motivation</h2><h2 id="3-Main-Arguments-1"><a href="#3-Main-Arguments-1" class="headerlink" title="3. Main Arguments"></a>3. Main Arguments</h2><p> &emsp;&emsp; 本篇论文提出了一种新的文本对抗攻击方法，是通过删除或替换文本中重要或突出的单词或在文本样本中引入新单词来实现的。该算法最适合在每个示例类中都有子类别的数据集。</p>
<h2 id="4-Framework-1"><a href="#4-Framework-1" class="headerlink" title="4. Framework"></a>4. Framework</h2><p> &emsp;&emsp; 作者采用了替换、插入、删除策略来进行修改，算法步骤如下：</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/4.png?raw=true"  alt="4"></p>
<h3 id="4-1-Calculate-contribution-of-each-word"><a href="#4-1-Calculate-contribution-of-each-word" class="headerlink" title="4.1 Calculate contribution of each word"></a>4.1 Calculate contribution of each word</h3><p> &emsp;&emsp; 如果将一个词移除后，类被概率发生了很大的改变，则说明这个单词是很重要的。因此，我们这样来定义一个单词的重要程度：</p>
<script type="math/tex; mode=display">
\mathcal{C}_{F}\left(w_{k}, y_{i}\right)=\left\{\begin{array}{l}
p_{F}\left(y_{i} \mid s\right)-p_{F}\left(y_{i} \mid s^{\mid w_{k}}\right), \text { if } F(s)=F\left(s^{\mid w_{k}}\right)=y_{i} \\
p_{F}\left(y_{i} \mid s\right)+p_{F}\left(y_{j} \mid s^{\mid w_{k}}\right), \text { if } F(s)=y_{i} \text { and } F\left(s^{\mid w_{k}}\right)=y_{j}
\end{array}\right.</script><p> &emsp;&emsp; 但是，对于一个大型的文本句子来说，上述的计算太耗时间，因此，作者又使用了FGSM的思想来估计单词的重要度：</p>
<script type="math/tex; mode=display">
\mathcal{C}_{F}(w_k,y) = -\nabla_{w_k}J(F,s,y_i)</script><p> &emsp;&emsp; 其中，$\ y<em>i$ 表示$\ s$ 的真是标签，$\ J$ 表示损失函数。在实际用的时候，我们是可以直接得到梯度$\ -\nabla</em>{s}J(F,s,y_i)$ 的。所以，这种方法比较快。</p>
<h3 id="4-2-Build-candidate-pool-P-for-each-word-in-sample-text"><a href="#4-2-Build-candidate-pool-P-for-each-word-in-sample-text" class="headerlink" title="4.2 Build candidate pool P for each word in sample text"></a>4.2 Build candidate pool P for each word in sample text</h3><p> &emsp;&emsp; 在有了这些分数之后，我们按照分数从大到小的顺序，依次的来修改单词。对于每个单词，我们需要为其建立候选池，我们可以考虑该词的同义词、拼写错误的词或者考虑类型或子类别特定的关键字。</p>
<h3 id="4-2-1-Synonyms-and-typos"><a href="#4-2-1-Synonyms-and-typos" class="headerlink" title="4.2.1 Synonyms and typos"></a>4.2.1 Synonyms and typos</h3><p> &emsp;&emsp; 使用同义词、以及容易拼写错误的单词，比如good单词容易拼写成god，将god加入good的候选池。</p>
<h3 id="4-2-2-Genre-specific-keywords"><a href="#4-2-2-Genre-specific-keywords" class="headerlink" title="4.2.2 Genre specific keywords"></a>4.2.2 Genre specific keywords</h3><p> &emsp;&emsp; 对于分类来说，比如情感分类，某些词可能对某一特定类型的电影产生积极的情绪，但对其他类型的电影可能会强调消极情绪。这些关键词通过考虑语料库中的词频（term frequencies, tf）来捕捉类的独特属性，如果一个词的次品对于一个特定类别的样本文本来说是高的，而对于属于不同类别的文本来说是低的，那么我们可以有把握地说，这个词对于第一类文本来说是独特的。我们用$\ \delta<em>i$ 来表示第$\ i$ 个类别中的独特的关键词。另外，我们考虑了单词的类型信息，将$\ \delta</em>{i,k}$ 表示为第$\ i$ 类别，第$\ k$ 类型的独特的关键词。我们扩充候选池：</p>
<script type="math/tex; mode=display">
P = P\ \cup \{\delta_j\ \cap \delta_{i,k} \}</script><p> &emsp;&emsp; 其中，$\ i \ne j$ ，$\ k$ 表示该单词的类型index（喜剧、恐怖片等）。这里我们其实考虑的是IMDB中两个类别的公共部分，加入到候选集中。这样，我们就忽略了类别独特的部分（sub-category）信息。所以，当我们添加这些单词到句子的时候，他们会往中间移动。</p>
<h3 id="4-3-Crafting-the-adversarial-sample"><a href="#4-3-Crafting-the-adversarial-sample" class="headerlink" title="4.3 Crafting the adversarial sample"></a>4.3 Crafting the adversarial sample</h3><p> &emsp;&emsp; 接下来，我们将描述，如何进行删除、添加和替换操作，假设原始样本为$\ s$ ，修改后的对抗样本为$\ s’$ ，目前正在操作的单词是$\ w_i$ 。我们按照每个单词的重要程度$\ C_F(w_i,y)$ 的顺序来处理单词。迭代的进行处理，直到生成对抗样本。</p>
<h4 id="4-3-1-Removal-of-words"><a href="#4-3-1-Removal-of-words" class="headerlink" title="4.3.1 Removal of words"></a>4.3.1 Removal of words</h4><p> &emsp;&emsp; 如果，$\ w_i$ 是副词，而且他的重要性$\ C_F(w_i,y)$ 很高，那么我们就移除这个单词。这是因为，副词起的是着重强调的意思，删除或者添加副词不会对句子的语法产生影响。</p>
<h4 id="4-3-2-Addition-of-words"><a href="#4-3-2-Addition-of-words" class="headerlink" title="4.3.2 Addition of words"></a>4.3.2 Addition of words</h4><p> &emsp;&emsp; 如果不满足4.3.1的条件，那么我们就从候选集中选择一个单词，我们选择：</p>
<script type="math/tex; mode=display">
j = \arg\min_k\ C_F(p_k,y)</script><p> &emsp;&emsp; 如果，$\ p_j$ 是副词而$\ w_i$ 是形容词的话，那么我们就在$\ w_i$ 的前面插入$\ p_j$ 。</p>
<h4 id="4-3-3-Replacement-of-word"><a href="#4-3-3-Replacement-of-word" class="headerlink" title="4.3.3 Replacement of word"></a>4.3.3 Replacement of word</h4><p> &emsp;&emsp; 如果不满足上面两个条件，那么，我们就是用$\ p_j$ 来替换$\ w_i$ 。但是，如果$\ p_j$ 是从Genre specific keywords  集合中得到的话，只有$\ p_j$ 与$\ w_i$ 词性相同的时候，我们才进行替换，如果不相同，那么我们就从候选集中找下一个合适的词来替换。词性相同用来保证我们生成的句子不容易被人类发现。</p>
<h2 id="5-Result-1"><a href="#5-Result-1" class="headerlink" title="5.Result"></a>5.Result</h2><h3 id="5-1-Performance"><a href="#5-1-Performance" class="headerlink" title="5.1 Performance"></a>5.1 Performance</h3><p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/5.png?raw=true"  alt="5"></p>
<h2 id="6-Argument-1"><a href="#6-Argument-1" class="headerlink" title="6. Argument"></a>6. Argument</h2><p> &emsp;&emsp; 对单词的删除、替换和添加都做了条件，同时考虑了子类别信息，引入了公共关键词，使得生成的对抗样本更具备攻击性。</p>
<h2 id="7-Further-research-1"><a href="#7-Further-research-1" class="headerlink" title="7. Further research"></a>7. Further research</h2><h1 id="三、Deep-Text-Classification-Can-be-Fooled"><a href="#三、Deep-Text-Classification-Can-be-Fooled" class="headerlink" title="三、Deep Text Classification Can be Fooled"></a>三、Deep Text Classification Can be Fooled</h1><h2 id="1-Paper-Information-2"><a href="#1-Paper-Information-2" class="headerlink" title="1. Paper Information"></a>1. Paper Information</h2><blockquote>
<p>时间：2018年</p>
<p>关键词：Adversarial Attack，White-box，Black-box，Word-level，Character-level，Target Attack</p>
<p>论文位置：<a href="https://arxiv.org/ftp/arxiv/papers/1704/1704.08006.pdf" target="_blank" rel="noopener">https://arxiv.org/ftp/arxiv/papers/1704/1704.08006.pdf</a></p>
<p>引用：Liang B, Li H, Su M, et al. Deep text classification can be fooled[J]. arXiv preprint arXiv:1704.08006, 2017.</p>
</blockquote>
<h2 id="2-Motivation-2"><a href="#2-Motivation-2" class="headerlink" title="2. Motivation"></a>2. Motivation</h2><h2 id="3-Main-Arguments-2"><a href="#3-Main-Arguments-2" class="headerlink" title="3. Main Arguments"></a>3. Main Arguments</h2><p> &emsp;&emsp; 本论文提出一种新的有效地生成文本对抗样本的方法，使用了插入、修改和删除的策略，在白盒攻击和黑盒攻击场景下获得了对抗样本。在白盒攻击下，我们利用梯度信息来决定如何、在哪进行插入、修改和删除。在黑盒攻击下，我们生成一些测试样本进行探测来获得上述的信息。</p>
<h2 id="4-Framework-2"><a href="#4-Framework-2" class="headerlink" title="4. Framework"></a>4. Framework</h2><h3 id="4-1-White-box-Attack"><a href="#4-1-White-box-Attack" class="headerlink" title="4.1 White-box Attack"></a>4.1 White-box Attack</h3><p> &emsp;&emsp; 在白盒攻击中，我们首先利用梯度信息，识别文本中哪个部分是重要的，利用这些信息来决定如何修改。</p>
<h4 id="4-1-1-Identifying-Classification-important-Items"><a href="#4-1-1-Identifying-Classification-important-Items" class="headerlink" title="4.1.1 Identifying Classification-important Items"></a>4.1.1 Identifying Classification-important Items</h4><p> &emsp;&emsp; 对于chartacter-level来说，<strong>我们利用梯度信息得到影响句子最大的字符，我们选择前50个为hot字符，包含三个以上hot字符的单词被称为hot单词，两个相邻的hot单词组成hot短语（hot单词也属于hot短语）</strong>。对于word-level来说，我们可以直接利用梯度信息得到hot单词。我们按照出现的次数排序，<strong>将最频繁出现的hot短语称之为Hot Training Phrases (HTPs)</strong>。HTPs阐明了插入什么，但是没有说明在哪里插入、删除和修改。</p>
<p> &emsp;&emsp; <strong>我们又利用梯度信息来定位那些对当前分类最有贡献的短语，将其称为Hot Sample Phrases（HSPs）</strong>。HSPs阐明了在哪里进行操作。</p>
<h4 id="4-1-2-Attacking-Character-level-DNN"><a href="#4-1-2-Attacking-Character-level-DNN" class="headerlink" title="4.1.2 Attacking Character-level DNN"></a>4.1.2 Attacking Character-level DNN</h4><p> &emsp;&emsp; 主要使用了三种策略，插入、修改和删除，这里针对的是目标攻击。</p>
<h5 id="4-1-2-1-Insertion-Strategy"><a href="#4-1-2-1-Insertion-Strategy" class="headerlink" title="4.1.2.1 Insertion Strategy"></a>4.1.2.1 Insertion Strategy</h5><p> &emsp;&emsp; 在插入时，我们将HTP插入到HSP前，如：</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/6.png?raw=true"  alt="6"></p>
<p> &emsp;&emsp; 当然，我们也会遇到插入很多个HTP的情况，这会使对抗样本的可读性变差。为了解决这个问题并丰富攻击方法，我们<strong>引入了自然语言处理的水印技术</strong>，比如同义词或拼写错误单词的替换、释义表示（paraphrasing representation ）、增加预设（adding presuppositions ）、插入语义空短语（inserting semantically empty phrases）。事实上，对抗扰动也可以被视为一种水印技术，用类似的方式嵌入到文本中。</p>
<p> &emsp;&emsp; 在这里，我们通过插入预设和语义空短语来扰动目标文本。预设是读者所熟知的隐含信息，一个语义空洞的短语是必不可少的组成部分，不管有没有它们，文本的意义都没有改变。通常，我们考虑通过将它们组装到一个语法单元中并将其插入到适当的位置来引入多个HTP。新单元可以被设计成可有可无的事实(见图3)，甚至可以被设计成不损害文本主要语义的伪造事实(见图4)。</p>
<p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/7.png?raw=true"  alt="7"></p>
<p> &emsp;&emsp; 具体来说，通过搜索互联网或一些事实数据库，我们可以得到一些与插入点密切相关的事实，也可以包含目标类的一些理想的HTP。例如，如图3所示，我们谷歌搜索“YG Entertainment”，我们可以从维基百科中很容易得到公司类的三个HTP(“company”、“founded”和“Entertainment”)。在公司名称后插入它可以制造一个有效的对抗样本，而不会引起人类观察者的注意。一个适当的事实是不可得时，我们提出一个新的概念，称为伪造事实，包装理想的HTPs。伪造的事实可以通过改造一些与HTPs有关的真实事物来创造，使人们相信它是真实发生的。此外，我们排除了伪造事实，可以通过检索相反的证据在互联网上被推翻。图4显示了一个伪造的事实，它携带了令人满意的HTP(“romantic”, “movie”, “directed by” and “American”)，愚弄了目标DNN。</p>
<h5 id="4-1-2-2-Modification-Strategy"><a href="#4-1-2-2-Modification-Strategy" class="headerlink" title="4.1.2.2 Modification Strategy"></a>4.1.2.2 Modification Strategy</h5><p> &emsp;&emsp; 我们使用同义词或者容易写出的错别拼写或者是一些相似的字符（比如小写的l与数字1）来替换HSP。</p>
<h5 id="4-1-2-3-Removal-Strategy"><a href="#4-1-2-3-Removal-Strategy" class="headerlink" title="4.1.2.3 Removal Strategy"></a>4.1.2.3 Removal Strategy</h5><p> &emsp;&emsp; 删除策略往往不是那么有效，但会极大地降低原始类别的置信度。</p>
<h4 id="4-1-3-Attacking-Word-level-DNN"><a href="#4-1-3-Attacking-Word-level-DNN" class="headerlink" title="4.1.3 Attacking Word-level DNN"></a>4.1.3 Attacking Word-level DNN</h4><p> &emsp;&emsp; Word-level的攻击与character-level很相似</p>
<h3 id="4-2-Black-box-Attack"><a href="#4-2-Black-box-Attack" class="headerlink" title="4.2 Black-box Attack"></a>4.2 Black-box Attack</h3><p> &emsp;&emsp; 在黑盒模型中，我们无法获得梯度信息。我们利用了fuzzing（模糊测试）技术来实现对HTP和HSP的定位。通过复杂地生成大量畸形输入，fuzzing可以触发意想不到的系统行为(例如，系统崩溃)，从而发现潜在的安全漏洞，甚至在不了解目标系统详细信息的情况下。同样，在我们提出的方法中，有目的地生成一些测试样本来探测目标模型。</p>
<p> &emsp;&emsp; 给定样本为种子样本，我们用空格来mask掉某个单词送入样本，检查该样本与种子样本的分类结果差异，来判断重视程度，从而确定HTP和HSP。</p>
<p> &emsp;&emsp; <strong>不论是白盒攻击还是黑盒攻击，我们会记录每个类别的HTP，在攻击时，使用不同类别的HTP进行插入、删除或替换从而实现目标攻击。</strong></p>
<h2 id="5-Result-2"><a href="#5-Result-2" class="headerlink" title="5.Result"></a>5.Result</h2><p><img src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/loading.gif?raw=true" class="lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/9.png?raw=true"  alt="9"></p>
<h2 id="6-Argument-2"><a href="#6-Argument-2" class="headerlink" title="6. Argument"></a>6. Argument</h2><p> &emsp;&emsp; 检测了不同类别的Hot词语，通过插入、删除或修改这些Hot词语进入样本实现目标攻击，但是实验样本数目太少了。</p>
<h2 id="7-Further-research-2"><a href="#7-Further-research-2" class="headerlink" title="7. Further research"></a>7. Further research</h2></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">白丁</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://baidinghub.github.io/2021/03/01/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/">http://baidinghub.github.io/2021/03/01/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://baidinghub.github.io" target="_blank">BaiDing's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/">文本对抗攻击</a><a class="post-meta__tags" href="/tags/Word-Level/">Word-Level</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDyIdOn/M/aXcGQOiSDVMqvN2gxDdiESHUfFuB2YMy48fvNN9SZOQUbVlGF4Pk6nDXIAir+br/EWuEnNLtgOCYMo/BTxl29gqS/QGHPiDaIQedzmLcuRZpfDuGit61N/b9pyktpZLagBgbl5Ox9mAgWQxXyhxYB092gyOXqrBULBeZUYQ+H7Eupha10QTQghHv4nLk+oYWo2UXEiijQpE3qMXT32G8v8k0KbRdd1hIFPyNEx6eZ6Buc2ZdbMtoutdGjvdnw5B1+dxgl1egESPChzcwCMxt3NW/3faQ5lsjRhQD4fRU+Ua/aqXe+0xg2+xr0BTjNr/JZIAaNiLuo71lH 1564026260@qq.com" async="async"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/wechat.png?raw=true" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/alipay.jpg?raw=true" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2021/03/01/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89/"><img class="prev_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89/cover.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">文本对抗攻击之Word-Level笔记系列（二）</div></div></a></div><div class="next-post pull_right"><a href="/2020/09/23/NLP%E8%AF%8D%E5%90%91%E9%87%8F%E7%AF%87%EF%BC%88%E5%85%AB%EF%BC%89ALBERT/"><img class="next_cover lazyload" data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E8%AF%8D%E5%90%91%E9%87%8F%E7%AF%87%EF%BC%88%E5%85%AB%EF%BC%89ALBERT/cover.png?raw=true" onerror="onerror=null;src='https://github.com/BaiDingHub/Blog_images/blob/master/BlogSource/404.jpg?raw=true'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">NLP词向量篇（八）ALBERT</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2021/03/01/文本对抗攻击之Word-Level笔记系列（二）/" title="文本对抗攻击之Word-Level笔记系列（二）"><img class="relatedPosts_cover lazyload"data-src="https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89/cover.png?raw=true"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-03-01</div><div class="relatedPosts_title">文本对抗攻击之Word-Level笔记系列（二）</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'd3948be001a91411dfd9',
  clientSecret: 'ebddf2a2a5a039922fb373a8a8c0efcc439bf6ca',
  repo: 'BaiDingHub.github.io',
  owner: 'BaiDingHub',
  admin: ['BaiDingHub'],
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" style="background-image: url(https://github.com/BaiDingHub/Blog_images/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97/%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B9%8BWord-Level%E7%AC%94%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/cover.png?raw=true)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 白丁</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://jerryc.me/" target="_blank" rel="noopener">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js" ></script><script src="/js/utils.js" ></script><script src="/js/main.js" ></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/search/algolia.js"></script></body></html>